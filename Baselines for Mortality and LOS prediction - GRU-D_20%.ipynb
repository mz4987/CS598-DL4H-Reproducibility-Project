{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "#from mmd_grud_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbaa070ef90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FILEPATH     = '../data/20%/all_hourly_data_7000.h5'\n",
    "RAW_DATA_FILEPATH = '../data/20%_arr/all_hourly_data_7000.h5'\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 2.9 s, total: 7.2 s\n",
      "Wall time: 8.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LEVEL2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">alanine aminotransferase</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin ascites</th>\n",
       "      <th>albumin pleural</th>\n",
       "      <th>...</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">white blood cell count urine</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph urine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Aggregation Function</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">145834</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">211552</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.147733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "LEVEL2                                 alanine aminotransferase             \\\n",
       "Aggregation Function                                      count  mean  std   \n",
       "subject_id hadm_id icustay_id hours_in                                       \n",
       "3          145834  211552     0                             2.0  25.0  0.0   \n",
       "                              1                             0.0   NaN  NaN   \n",
       "                              2                             0.0   NaN  NaN   \n",
       "                              3                             0.0   NaN  NaN   \n",
       "                              4                             0.0   NaN  NaN   \n",
       "\n",
       "LEVEL2                                 albumin           albumin ascites       \\\n",
       "Aggregation Function                     count mean  std           count mean   \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0            2.0  1.8  0.0             0.0  NaN   \n",
       "                              1            0.0  NaN  NaN             0.0  NaN   \n",
       "                              2            0.0  NaN  NaN             0.0  NaN   \n",
       "                              3            0.0  NaN  NaN             0.0  NaN   \n",
       "                              4            0.0  NaN  NaN             0.0  NaN   \n",
       "\n",
       "LEVEL2                                     albumin pleural  ...  \\\n",
       "Aggregation Function                   std           count  ...   \n",
       "subject_id hadm_id icustay_id hours_in                      ...   \n",
       "3          145834  211552     0        NaN             0.0  ...   \n",
       "                              1        NaN             0.0  ...   \n",
       "                              2        NaN             0.0  ...   \n",
       "                              3        NaN             0.0  ...   \n",
       "                              4        NaN             0.0  ...   \n",
       "\n",
       "LEVEL2                                 white blood cell count  \\\n",
       "Aggregation Function                                      std   \n",
       "subject_id hadm_id icustay_id hours_in                          \n",
       "3          145834  211552     0                      4.012837   \n",
       "                              1                           NaN   \n",
       "                              2                           NaN   \n",
       "                              3                           NaN   \n",
       "                              4                           NaN   \n",
       "\n",
       "LEVEL2                                 white blood cell count urine           \\\n",
       "Aggregation Function                                          count mean std   \n",
       "subject_id hadm_id icustay_id hours_in                                         \n",
       "3          145834  211552     0                                 0.0  NaN NaN   \n",
       "                              1                                 0.0  NaN NaN   \n",
       "                              2                                 0.0  NaN NaN   \n",
       "                              3                                 0.0  NaN NaN   \n",
       "                              4                                 0.0  NaN NaN   \n",
       "\n",
       "LEVEL2                                    ph                 ph urine           \n",
       "Aggregation Function                   count  mean       std    count mean std  \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0          9.0  7.40  0.147733      1.0  5.0 NaN  \n",
       "                              1          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              2          3.0  7.26  0.000000      0.0  NaN NaN  \n",
       "                              3          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              4          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_full_raw.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>age</th>\n",
       "      <th>insurance</th>\n",
       "      <th>admittime</th>\n",
       "      <th>diagnosis_at_admission</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>fullcode_first</th>\n",
       "      <th>dnr_first</th>\n",
       "      <th>...</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>mort_icu</th>\n",
       "      <th>mort_hosp</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>hospstay_seq</th>\n",
       "      <th>readmission_30</th>\n",
       "      <th>max_hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>145834</th>\n",
       "      <th>211552</th>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>76.526792</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>HYPOTENSION</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>SNF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2101-10-26 20:43:09</td>\n",
       "      <td>6.064560</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>185777</th>\n",
       "      <th>294638</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47.845047</td>\n",
       "      <td>Private</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>FEVER,DEHYDRATION,FAILURE TO THRIVE</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>HOME WITH HOME IV PROVIDR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2191-03-17 16:46:31</td>\n",
       "      <td>1.678472</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>107064</th>\n",
       "      <th>228232</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>65.942297</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>CHRONIC RENAL FAILURE/SDA</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2175-06-03 13:39:54</td>\n",
       "      <td>3.672917</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>150750</th>\n",
       "      <th>220597</th>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>41.790228</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2149-11-09 13:06:00</td>\n",
       "      <td>HEMORRHAGIC CVA</td>\n",
       "      <td>2149-11-14 10:15:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2149-11-14 20:52:14</td>\n",
       "      <td>5.323056</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>194540</th>\n",
       "      <th>229441</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>50.148295</td>\n",
       "      <td>Private</td>\n",
       "      <td>2178-04-16 06:18:00</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>2178-05-11 19:00:00</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2178-04-17 20:21:05</td>\n",
       "      <td>1.584410</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              gender              ethnicity        age  \\\n",
       "subject_id hadm_id icustay_id                                            \n",
       "3          145834  211552          M                  WHITE  76.526792   \n",
       "4          185777  294638          F                  WHITE  47.845047   \n",
       "6          107064  228232          F                  WHITE  65.942297   \n",
       "9          150750  220597          M  UNKNOWN/NOT SPECIFIED  41.790228   \n",
       "11         194540  229441          F                  WHITE  50.148295   \n",
       "\n",
       "                              insurance           admittime  \\\n",
       "subject_id hadm_id icustay_id                                 \n",
       "3          145834  211552      Medicare 2101-10-20 19:08:00   \n",
       "4          185777  294638       Private 2191-03-16 00:28:00   \n",
       "6          107064  228232      Medicare 2175-05-30 07:15:00   \n",
       "9          150750  220597      Medicaid 2149-11-09 13:06:00   \n",
       "11         194540  229441       Private 2178-04-16 06:18:00   \n",
       "\n",
       "                                            diagnosis_at_admission  \\\n",
       "subject_id hadm_id icustay_id                                        \n",
       "3          145834  211552                              HYPOTENSION   \n",
       "4          185777  294638      FEVER,DEHYDRATION,FAILURE TO THRIVE   \n",
       "6          107064  228232                CHRONIC RENAL FAILURE/SDA   \n",
       "9          150750  220597                          HEMORRHAGIC CVA   \n",
       "11         194540  229441                               BRAIN MASS   \n",
       "\n",
       "                                        dischtime         discharge_location  \\\n",
       "subject_id hadm_id icustay_id                                                  \n",
       "3          145834  211552     2101-10-31 13:58:00                        SNF   \n",
       "4          185777  294638     2191-03-23 18:41:00  HOME WITH HOME IV PROVIDR   \n",
       "6          107064  228232     2175-06-15 16:00:00           HOME HEALTH CARE   \n",
       "9          150750  220597     2149-11-14 10:15:00               DEAD/EXPIRED   \n",
       "11         194540  229441     2178-05-11 19:00:00           HOME HEALTH CARE   \n",
       "\n",
       "                               fullcode_first  dnr_first  ...  \\\n",
       "subject_id hadm_id icustay_id                             ...   \n",
       "3          145834  211552                 1.0        0.0  ...   \n",
       "4          185777  294638                 1.0        0.0  ...   \n",
       "6          107064  228232                 1.0        0.0  ...   \n",
       "9          150750  220597                 1.0        0.0  ...   \n",
       "11         194540  229441                 1.0        0.0  ...   \n",
       "\n",
       "                                          outtime   los_icu admission_type  \\\n",
       "subject_id hadm_id icustay_id                                                \n",
       "3          145834  211552     2101-10-26 20:43:09  6.064560      EMERGENCY   \n",
       "4          185777  294638     2191-03-17 16:46:31  1.678472      EMERGENCY   \n",
       "6          107064  228232     2175-06-03 13:39:54  3.672917       ELECTIVE   \n",
       "9          150750  220597     2149-11-14 20:52:14  5.323056      EMERGENCY   \n",
       "11         194540  229441     2178-04-17 20:21:05  1.584410      EMERGENCY   \n",
       "\n",
       "                              first_careunit  mort_icu  mort_hosp  \\\n",
       "subject_id hadm_id icustay_id                                       \n",
       "3          145834  211552               MICU         0          0   \n",
       "4          185777  294638               MICU         0          0   \n",
       "6          107064  228232               SICU         0          0   \n",
       "9          150750  220597               MICU         1          1   \n",
       "11         194540  229441               SICU         0          0   \n",
       "\n",
       "                               hospital_expire_flag hospstay_seq  \\\n",
       "subject_id hadm_id icustay_id                                      \n",
       "3          145834  211552                         0            1   \n",
       "4          185777  294638                         0            1   \n",
       "6          107064  228232                         0            1   \n",
       "9          150750  220597                         1            1   \n",
       "11         194540  229441                         0            1   \n",
       "\n",
       "                              readmission_30 max_hours  \n",
       "subject_id hadm_id icustay_id                           \n",
       "3          145834  211552                  0       145  \n",
       "4          185777  294638                  0        40  \n",
       "6          107064  228232                  0        88  \n",
       "9          150750  220597                  0       127  \n",
       "11         194540  229441                  0        38  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengxuan/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1884: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, val, pi)\n"
     ]
    }
   ],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "\n",
    "lvl2, raw = [df[\n",
    "    (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] for df in (data_full_lvl2, data_full_raw)]\n",
    "\n",
    "#raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "#assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, raw, Ys)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "#raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "\n",
    "#raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "#raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "#raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test = [\n",
    "#    simple_imputer(df) for df in (raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test)\n",
    "#]\n",
    "#raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "#    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "#        raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test\n",
    "#    )\n",
    "#]\n",
    "\n",
    "#for df in lvl2_train, lvl2_dev, lvl2_test, raw_train, raw_dev, raw_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengxuan/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "lvl2_train, lvl2_dev, lvl2_test = [\n",
    "    simple_imputer(df) for df in (lvl2_train, lvl2_dev, lvl2_test)\n",
    "]\n",
    "lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        lvl2_train, lvl2_dev, lvl2_test\n",
    "    )\n",
    "]\n",
    "\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test: assert not df.isnull().any().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "[(Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (Ys,)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "GRU_D_dist = DictDist({\n",
    "    'cell_size': ss.randint(50, 75),\n",
    "    'hidden_size': ss.randint(65, 95), \n",
    "    'learning_rate': ss.uniform(2e-3, 1e-1),\n",
    "    'num_epochs': ss.randint(15, 150),\n",
    "    'patience': ss.randint(3, 7),\n",
    "    'batch_size': ss.randint(35, 65),\n",
    "    'early_stop_frac': ss.uniform(0.05, 0.1),\n",
    "    'seed': ss.randint(1, 10000),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "GRU_D_hyperparams_list = GRU_D_dist.rvs(N)\n",
    "\n",
    "#with open('../scratch/mmd/baselines_gru-d.pkl', mode='rb') as f: results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "def to_3D_tensor(df):\n",
    "    idx = pd.IndexSlice\n",
    "    return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
    "def prepare_dataloader(df, Ys, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    dfs = (df_train, df_dev, df_test).\n",
    "    df_* = (subject, hadm, icustay, hours_in) X (level2, agg fn \\ni {mask, mean, time})\n",
    "    Ys_series = (subject, hadm, icustay) => label.\n",
    "    \"\"\"\n",
    "    X     = torch.from_numpy(to_3D_tensor(df).astype(np.float32))\n",
    "    #print(X[:5])\n",
    "    label = torch.from_numpy(Ys.values.astype(np.int64))\n",
    "    dataset = utils.TensorDataset(X, label)\n",
    "    \n",
    "    return utils.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last = True)\n",
    "\n",
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        assert in_features > 1 and out_features > 1, \"Passing in nonsense sizes\"\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu: self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:       self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "\n",
    "        if bias: self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:    self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None: self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.filter_square_matrix.mul(self.weight),\n",
    "            self.bias\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, X_mean, batch_size = 0, output_last = False):\n",
    "        \"\"\"\n",
    "        With minor modifications from https://github.com/zhiyongc/GRU-D/\n",
    "\n",
    "        Recurrent Neural Networks for Multivariate Times Series with Missing Values\n",
    "        GRU-D: GRU exploit two representations of informative missingness patterns, i.e., masking and time interval.\n",
    "        cell_size is the size of cell_state.\n",
    "        \n",
    "        Implemented based on the paper: \n",
    "        @article{che2018recurrent,\n",
    "          title={Recurrent neural networks for multivariate time series with missing values},\n",
    "          author={Che, Zhengping and Purushotham, Sanjay and Cho, Kyunghyun and Sontag, David and Liu, Yan},\n",
    "          journal={Scientific reports},\n",
    "          volume={8},\n",
    "          number={1},\n",
    "          pages={6085},\n",
    "          year={2018},\n",
    "          publisher={Nature Publishing Group}\n",
    "        }\n",
    "        \n",
    "        GRU-D:\n",
    "            input_size: variable dimension of each time\n",
    "            hidden_size: dimension of hidden_state\n",
    "            mask_size: dimension of masking vector\n",
    "            X_mean: the mean of the historical input data\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GRUD, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.delta_size = input_size\n",
    "        self.mask_size = input_size\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            self.identity = torch.eye(input_size).cuda()\n",
    "            self.zeros = Variable(torch.zeros(batch_size, input_size).cuda())\n",
    "            self.zeros_h = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean).cuda())\n",
    "        else:\n",
    "            self.identity = torch.eye(input_size)\n",
    "            self.zeros = Variable(torch.zeros(batch_size, input_size))\n",
    "            self.zeros_h = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean))\n",
    "        \n",
    "        self.zl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size) # Wz, Uz are part of the same network. the bias is bz\n",
    "        self.rl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size) # Wr, Ur are part of the same network. the bias is br\n",
    "        self.hl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size) # W, U are part of the same network. the bias is b\n",
    "        \n",
    "        self.gamma_x_l = FilterLinear(self.delta_size, self.delta_size, self.identity)\n",
    "        \n",
    "        self.gamma_h_l = nn.Linear(self.delta_size, self.hidden_size) # this was wrong in available version. remember to raise the issue\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size, 2)\n",
    "        self.bn= torch.nn.BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.drop=nn.Dropout(p=0.5, inplace=False)\n",
    "        \n",
    "    def step(self, x, x_last_obsv, x_mean, h, mask, delta):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x: input tensor\n",
    "            x_last_obsv: input tensor with forward fill applied\n",
    "            x_mean: the mean of each feature\n",
    "            h: the hidden state of the network\n",
    "            mask: the mask of whether or not the current value is observed\n",
    "            delta: the tensor indicating the number of steps since the last time a feature was observed.\n",
    "            \n",
    "        Returns:\n",
    "            h: the updated hidden state of the network\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = x.size()[0]\n",
    "        dim_size = x.size()[1]\n",
    "        \n",
    "        gamma_x_l_delta = self.gamma_x_l(delta)\n",
    "        delta_x = torch.exp(-torch.max(self.zeros, gamma_x_l_delta)) #exponentiated negative rectifier\n",
    "        \n",
    "        gamma_h_l_delta = self.gamma_h_l(delta)\n",
    "        delta_h = torch.exp(-torch.max(self.zeros_h, gamma_h_l_delta)) #self.zeros became self.zeros_h to accomodate hidden size != input size\n",
    "        \n",
    "        x_mean = x_mean.repeat(batch_size, 1)\n",
    "   \n",
    "        x = mask * x + (1 - mask) * (delta_x * x_last_obsv + (1 - delta_x) * x_mean)\n",
    "        x = torch.nan_to_num(x)\n",
    "        \n",
    "        h = delta_h * h\n",
    "       \n",
    "        combined = torch.cat((x, h, mask), 1)\n",
    "        z = torch.sigmoid(self.zl(combined)) #sigmoid(W_z*x_t + U_z*h_{t-1} + V_z*m_t + bz)\n",
    "        r = torch.sigmoid(self.rl(combined)) #sigmoid(W_r*x_t + U_r*h_{t-1} + V_r*m_t + br)\n",
    "        combined_new = torch.cat((x, r*h, mask), 1)\n",
    "        h_tilde = torch.tanh(self.hl(combined_new)) #tanh(W*x_t +U(r_t*h_{t-1}) + V*m_t) + b\n",
    "        h = (1 - z) * h + z * h_tilde\n",
    "        h = torch.nan_to_num(h)\n",
    "        return h\n",
    "    \n",
    "    def forward(self, X, X_last_obsv, Mask, Delta):\n",
    "        batch_size = X.size(0)\n",
    "#         type_size = input.size(1)\n",
    "        step_size = X.size(1) # num timepoints\n",
    "        spatial_size = X.size(2) # num features\n",
    "        \n",
    "        Hidden_State = self.initHidden(batch_size)\n",
    "#         X = torch.squeeze(input[:,0,:,:])\n",
    "#         X_last_obsv = torch.squeeze(input[:,1,:,:])\n",
    "#         Mask = torch.squeeze(input[:,2,:,:])\n",
    "#         Delta = torch.squeeze(input[:,3,:,:])\n",
    "        \n",
    "        outputs = None\n",
    "        for i in range(step_size):\n",
    "            Hidden_State = self.step(\n",
    "                torch.squeeze(X[:,i:i+1,:], 1),\n",
    "                torch.squeeze(X_last_obsv[:,i:i+1,:], 1),\n",
    "                torch.squeeze(self.X_mean[:,i:i+1,:], 1),\n",
    "                Hidden_State,\n",
    "                torch.squeeze(Mask[:,i:i+1,:], 1),\n",
    "                torch.squeeze(Delta[:,i:i+1,:], 1),\n",
    "            )\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((Hidden_State.unsqueeze(1), outputs), 1)\n",
    "                \n",
    "        # we want to predict a binary outcome\n",
    "        #Apply 50% dropout and batch norm here\n",
    "        self.drop(self.bn(self.fc(Hidden_State)))\n",
    "        return self.drop(self.bn(self.fc(Hidden_State)))\n",
    "                \n",
    "#         if self.output_last:\n",
    "#             return outputs[:,-1,:]\n",
    "#         else:\n",
    "#             return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Train_Model(\n",
    "    model, train_dataloader, valid_dataloader, num_epochs = 300, patience = 3, min_delta = 1e-5, learning_rate=1e-3, batch_size=None\n",
    "):\n",
    "    \n",
    "    print('Model Structure: ', model)\n",
    "    print('Start Training ... ')\n",
    "    \n",
    "    model\n",
    "    \n",
    "    if (type(model) == nn.modules.container.Sequential):\n",
    "        output_last = model[-1].output_last\n",
    "        print('Output type dermined by the last layer')\n",
    "    else:\n",
    "        output_last = model.output_last\n",
    "        print('Output type dermined by the model')\n",
    "        \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_nll=torch.nn.NLLLoss()\n",
    "    loss_CEL=torch.nn.CrossEntropyLoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate, alpha=0.99)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    use_gpu = False#torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "        \n",
    "        for X, labels in train_dataloader:\n",
    "            X = X.numpy()\n",
    "         \n",
    "            mask        = torch.from_numpy(X[:, np.arange(0, X.shape[1], 3), :].astype(np.float32))\n",
    "            measurement = torch.from_numpy(X[:, np.arange(1, X.shape[1], 3), :].astype(np.float32))\n",
    "            time_       = torch.from_numpy(X[:, np.arange(2, X.shape[1], 3), :].astype(np.float32))\n",
    "            \n",
    "            mask = torch.transpose(mask, 1, 2)\n",
    "            measurement = torch.transpose(measurement, 1, 2)\n",
    "            time_ = torch.transpose(time_, 1, 2)\n",
    "            measurement_last_obsv = measurement            \n",
    "\n",
    "            assert measurement.size()[0] == batch_size, \"Batch Size doesn't match! %s\" % str(measurement.size())\n",
    "\n",
    "            if use_gpu:\n",
    "                convert_to_cuda=lambda x: Variable(x.cuda())\n",
    "                X, X_last_obsv, Mask, Delta, labels = map(convert_to_cuda, [measurement, measurement_last_obsv, mask, time_, labels])\n",
    "            else: \n",
    "#                 inputs, labels = Variable(inputs), Variable(labels)\n",
    "                convert_to_tensor=lambda x: Variable(x)\n",
    "                X, X_last_obsv, Mask, Delta, labels  = map(convert_to_tensor, [measurement, measurement_last_obsv, mask, time_, labels])\n",
    "            \n",
    "            model.zero_grad()\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "            prediction=model(X, X_last_obsv, Mask, Delta)\n",
    "    \n",
    "#             print(torch.sum(torch.sum(torch.isnan(prediction))))\n",
    "            \n",
    "#             print(labels.shape)\n",
    "#             print(prediction.shape)\n",
    "            \n",
    "            if output_last:\n",
    "                loss_train = loss_CEL(torch.squeeze(prediction), torch.squeeze(labels))\n",
    "            else:\n",
    "                full_labels = torch.cat((inputs[:,1:,:], labels), dim = 1)\n",
    "                loss_train = loss_MSE(outputs, full_labels)\n",
    "                \n",
    "      \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "             # validation \n",
    "            try: \n",
    "                X_val, labels_val = next(valid_dataloader_iter)\n",
    "                X_val = X_val.numpy()\n",
    "                mask_val        = torch.from_numpy(X_val[:, np.arange(0, X_val.shape[1], 3), :].astype(np.float32))\n",
    "                measurement_val = torch.from_numpy(X_val[:, np.arange(1, X_val.shape[1], 3), :].astype(np.float32))\n",
    "                time_val       = torch.from_numpy(X_val[:, np.arange(2, X_val.shape[1], 3), :].astype(np.float32))\n",
    "            \n",
    "                mask_val = torch.transpose(mask_val, 1, 2)\n",
    "                measurement_val = torch.transpose(measurement_val, 1, 2)\n",
    "                time_val = torch.transpose(time_val, 1, 2)\n",
    "                measurement_last_obsv_val = measurement_val\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                X_val, labels_val = next(valid_dataloader_iter)\n",
    "                X_val = X_val.numpy()\n",
    "                mask_val        = torch.from_numpy(X_val[:, np.arange(0, X_val.shape[1], 3), :].astype(np.float32))\n",
    "                measurement_val = torch.from_numpy(X_val[:, np.arange(1, X_val.shape[1], 3), :].astype(np.float32))\n",
    "                time_val       = torch.from_numpy(X_val[:, np.arange(2, X_val.shape[1], 3), :].astype(np.float32))\n",
    "            \n",
    "                mask_val = torch.transpose(mask_val, 1, 2)\n",
    "                measurement_val = torch.transpose(measurement_val, 1, 2)\n",
    "                time_val = torch.transpose(time_val, 1, 2)\n",
    "                measurement_last_obsv_val = measurement_val\n",
    "            \n",
    "            if use_gpu:\n",
    "                convert_to_cuda=lambda x: Variable(x.cuda())\n",
    "                X_val, X_last_obsv_val, Mask_val, Delta_val, labels_val = map(convert_to_cuda, [measurement_val, measurement_last_obsv_val, mask_val, time_val, labels_val])\n",
    "            else: \n",
    "#                 inputs, labels = Variable(inputs), Variable(labels)\n",
    "                convert_to_tensor=lambda x: Variable(x)\n",
    "                X_val, X_last_obsv_val, Mask_val, Delta_val, labels_val = map(convert_to_tensor, [measurement_val, measurement_last_obsv_val, mask_val, time_val, labels_val])\n",
    "            \n",
    "                \n",
    "            model.zero_grad()\n",
    "            \n",
    "#             outputs_val = model(inputs_val)\n",
    "            prediction_val = model(X_val, X_last_obsv_val, Mask_val, Delta_val)\n",
    "    \n",
    "#             print(labels.shape)\n",
    "#             print(prediction_val.shape)\n",
    "            \n",
    "            if output_last:\n",
    "                loss_valid =loss_CEL(torch.squeeze(prediction_val), torch.squeeze(labels_val))\n",
    "            else:\n",
    "                raise NotImplementedError(\"Should be output last!\")\n",
    "                full_labels_val = torch.cat((inputs_val[:,1:,:], labels_val), dim = 1)\n",
    "                loss_valid = loss_MSE(outputs_val, full_labels_val)\n",
    "                \n",
    "          \n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "#             print(sklearn.metrics.roc_auc_score(labels_val.detach().cpu().numpy(), prediction_val.detach().cpu().numpy()[:,1]))\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train).cpu().numpy() / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid).cpu().numpy() / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                    epoch, \\\n",
    "                    np.around(avg_losses_epoch_train, decimals=8),\\\n",
    "                    np.around(avg_losses_epoch_valid, decimals=8),\\\n",
    "                    np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                    is_best_model) )\n",
    "        pre_time = cur_time\n",
    "#         if epoch==1:\n",
    "#             break\n",
    "                \n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_proba(model, dataloader):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        model: GRU-D model\n",
    "        test_dataloader: containing batches of measurement, measurement_last_obsv, mask, time_, labels\n",
    "    Returns:\n",
    "        predictions: size[num_samples, 2]\n",
    "        labels: size[num_samples]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    use_gpu = False# torch.cuda.is_available()\n",
    "    \n",
    "    probabilities = []\n",
    "    labels        = []\n",
    "    ethnicities   = []\n",
    "    genders       = []\n",
    "    for X, label in dataloader:\n",
    "        X = X.numpy()\n",
    "        mask        = torch.from_numpy(X[:, np.arange(0, X.shape[1], 3), :].astype(np.float32))\n",
    "        measurement = torch.from_numpy(X[:, np.arange(1, X.shape[1], 3), :].astype(np.float32))\n",
    "        time_       = torch.from_numpy(X[:, np.arange(2, X.shape[1], 3), :].astype(np.float32))\n",
    "\n",
    "        mask = torch.transpose(mask, 1, 2)\n",
    "        measurement = torch.transpose(measurement, 1, 2)\n",
    "        time_ = torch.transpose(time_, 1, 2)\n",
    "        measurement_last_obsv = measurement            \n",
    "\n",
    "        if use_gpu:\n",
    "            convert_to_cuda=lambda x: Variable(x.cuda())\n",
    "            X, X_last_obsv, Mask, Delta, label = map(convert_to_cuda, [measurement, measurement_last_obsv, mask, time_, label])\n",
    "        else: \n",
    "#                 inputs, labels = Variable(inputs), Variable(labels)\n",
    "            convert_to_tensor=lambda x: Variable(x)\n",
    "            X, X_last_obsv, Mask, Delta, label  = map(convert_to_tensor, [measurement, measurement_last_obsv, mask, time_, label])\n",
    "\n",
    "        \n",
    "        prob = model(X, X_last_obsv, Mask, Delta)\n",
    "        \n",
    "        probabilities.append(prob.detach().cpu().data.numpy())\n",
    "        labels.append(label.detach().cpu().data.numpy())\n",
    "\n",
    "    return probabilities, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GRU-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target mort_icu with representation lvl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
      "<timed exec>:18: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.84331091, valid_loss: 0.89763973, time: [4.84], best model: 1\n",
      "Epoch: 1, train_loss: 0.71245279, valid_loss: 0.7457945, time: [4.85], best model: 1\n",
      "Epoch: 2, train_loss: 0.62439868, valid_loss: 0.68408032, time: [4.89], best model: 1\n",
      "Epoch: 3, train_loss: 0.58089517, valid_loss: 0.62682363, time: [4.85], best model: 1\n",
      "Epoch: 4, train_loss: 0.52834651, valid_loss: 0.56839757, time: [4.88], best model: 1\n",
      "Epoch: 5, train_loss: 0.48787107, valid_loss: 0.53865729, time: [4.86], best model: 1\n",
      "Epoch: 6, train_loss: 0.45757143, valid_loss: 0.50642736, time: [4.83], best model: 1\n",
      "Epoch: 7, train_loss: 0.42600792, valid_loss: 0.46368569, time: [4.79], best model: 1\n",
      "Epoch: 8, train_loss: 0.40497428, valid_loss: 0.4606782, time: [4.79], best model: 1\n",
      "Epoch: 9, train_loss: 0.39237233, valid_loss: 0.43710116, time: [4.78], best model: 1\n",
      "Epoch: 10, train_loss: 0.3743111, valid_loss: 0.42175449, time: [4.78], best model: 1\n",
      "Epoch: 11, train_loss: 0.36107327, valid_loss: 0.40637087, time: [4.78], best model: 1\n",
      "Epoch: 12, train_loss: 0.34248272, valid_loss: 0.42683029, time: [4.85], best model: 0\n",
      "Epoch: 13, train_loss: 0.34486525, valid_loss: 0.40750102, time: [4.78], best model: 0\n",
      "Epoch: 14, train_loss: 0.32855641, valid_loss: 0.3980671, time: [4.83], best model: 1\n",
      "Epoch: 15, train_loss: 0.32768561, valid_loss: 0.37956072, time: [4.82], best model: 1\n",
      "Epoch: 16, train_loss: 0.31067088, valid_loss: 0.3810672, time: [4.84], best model: 0\n",
      "Epoch: 17, train_loss: 0.31080768, valid_loss: 0.3642103, time: [4.78], best model: 1\n",
      "Epoch: 18, train_loss: 0.2938243, valid_loss: 0.37266345, time: [4.84], best model: 0\n",
      "Epoch: 19, train_loss: 0.29802197, valid_loss: 0.35984571, time: [4.82], best model: 1\n",
      "Epoch: 20, train_loss: 0.28619197, valid_loss: 0.36090587, time: [4.89], best model: 0\n",
      "Epoch: 21, train_loss: 0.27556919, valid_loss: 0.37991069, time: [4.91], best model: 0\n",
      "New Best Score: 82.40 @ hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496}\n",
      "On sample 2 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (rl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (hl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=77, bias=True)\n",
      "  (fc): Linear(in_features=77, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81273672, valid_loss: 0.82484498, time: [5.84], best model: 1\n",
      "Epoch: 1, train_loss: 0.67443015, valid_loss: 0.6997259, time: [5.84], best model: 1\n",
      "Epoch: 2, train_loss: 0.57935975, valid_loss: 0.60333959, time: [5.85], best model: 1\n",
      "Epoch: 3, train_loss: 0.54449102, valid_loss: 0.55756926, time: [5.84], best model: 1\n",
      "Epoch: 4, train_loss: 0.48519076, valid_loss: 0.49162632, time: [5.84], best model: 1\n",
      "Epoch: 5, train_loss: 0.44339811, valid_loss: 0.45105209, time: [5.85], best model: 1\n",
      "Epoch: 6, train_loss: 0.41117034, valid_loss: 0.41494921, time: [5.85], best model: 1\n",
      "Epoch: 7, train_loss: 0.38460312, valid_loss: 0.39234526, time: [5.99], best model: 1\n",
      "Epoch: 8, train_loss: 0.35946707, valid_loss: 0.36997597, time: [5.87], best model: 1\n",
      "Epoch: 9, train_loss: 0.34968706, valid_loss: 0.35828466, time: [5.94], best model: 1\n",
      "Epoch: 10, train_loss: 0.33390309, valid_loss: 0.35028381, time: [5.89], best model: 1\n",
      "Epoch: 11, train_loss: 0.32925207, valid_loss: 0.33638677, time: [5.85], best model: 1\n",
      "Epoch: 12, train_loss: 0.31625144, valid_loss: 0.33409188, time: [5.89], best model: 1\n",
      "Epoch: 13, train_loss: 0.30011982, valid_loss: 0.32342124, time: [6.], best model: 1\n",
      "Epoch: 14, train_loss: 0.28920028, valid_loss: 0.32384765, time: [5.89], best model: 0\n",
      "Epoch: 15, train_loss: 0.28307365, valid_loss: 0.31820613, time: [5.85], best model: 1\n",
      "Epoch: 16, train_loss: 0.28021623, valid_loss: 0.32655036, time: [5.84], best model: 0\n",
      "Epoch: 17, train_loss: 0.2758221, valid_loss: 0.32783938, time: [5.86], best model: 0\n",
      "Epoch: 18, train_loss: 0.2741531, valid_loss: 0.3244838, time: [5.86], best model: 0\n",
      "Epoch: 19, train_loss: 0.2627539, valid_loss: 0.32421712, time: [5.85], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "On sample 3 / 10 (hyperparams = {'cell_size': 62, 'hidden_size': 72, 'learning_rate': 0.08981174363909455, 'num_epochs': 76, 'patience': 4, 'batch_size': 39, 'early_stop_frac': 0.14888610889064946, 'seed': 156})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (rl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (hl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=72, bias=True)\n",
      "  (fc): Linear(in_features=72, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.82480679, valid_loss: 0.79305362, time: [5.46], best model: 1\n",
      "Epoch: 1, train_loss: 0.6789808, valid_loss: 0.68401191, time: [5.37], best model: 1\n",
      "Epoch: 2, train_loss: 0.60798674, valid_loss: 0.58273686, time: [5.41], best model: 1\n",
      "Epoch: 3, train_loss: 0.55238255, valid_loss: 0.53647897, time: [5.46], best model: 1\n",
      "Epoch: 4, train_loss: 0.49699133, valid_loss: 0.50535464, time: [5.38], best model: 1\n",
      "Epoch: 5, train_loss: 0.4574921, valid_loss: 0.47499172, time: [5.42], best model: 1\n",
      "Epoch: 6, train_loss: 0.42164034, valid_loss: 0.43890148, time: [5.4], best model: 1\n",
      "Epoch: 7, train_loss: 0.38969694, valid_loss: 0.4186785, time: [5.45], best model: 1\n",
      "Epoch: 8, train_loss: 0.3723712, valid_loss: 0.40659634, time: [5.4], best model: 1\n",
      "Epoch: 9, train_loss: 0.35386356, valid_loss: 0.38669604, time: [5.39], best model: 1\n",
      "Epoch: 10, train_loss: 0.33368686, valid_loss: 0.37774139, time: [5.43], best model: 1\n",
      "Epoch: 11, train_loss: 0.32375975, valid_loss: 0.37684555, time: [5.39], best model: 1\n",
      "Epoch: 12, train_loss: 0.32133894, valid_loss: 0.36836025, time: [5.4], best model: 1\n",
      "Epoch: 13, train_loss: 0.30984123, valid_loss: 0.37013335, time: [5.56], best model: 0\n",
      "Epoch: 14, train_loss: 0.30556266, valid_loss: 0.365511, time: [5.58], best model: 1\n",
      "Epoch: 15, train_loss: 0.29631235, valid_loss: 0.36369487, time: [5.42], best model: 1\n",
      "Epoch: 16, train_loss: 0.28820123, valid_loss: 0.36074662, time: [5.59], best model: 1\n",
      "Epoch: 17, train_loss: 0.28117007, valid_loss: 0.37153902, time: [5.76], best model: 0\n",
      "Epoch: 18, train_loss: 0.27616595, valid_loss: 0.3640678, time: [5.52], best model: 0\n",
      "Epoch: 19, train_loss: 0.2749418, valid_loss: 0.37221818, time: [5.45], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "On sample 4 / 10 (hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (rl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (hl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=78, bias=True)\n",
      "  (fc): Linear(in_features=78, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.8438631, valid_loss: 0.79264552, time: [4.95], best model: 1\n",
      "Epoch: 1, train_loss: 0.72393836, valid_loss: 0.70476763, time: [5.02], best model: 1\n",
      "Epoch: 2, train_loss: 0.65161504, valid_loss: 0.64580348, time: [4.97], best model: 1\n",
      "Epoch: 3, train_loss: 0.60990691, valid_loss: 0.59192045, time: [5.03], best model: 1\n",
      "Epoch: 4, train_loss: 0.55421544, valid_loss: 0.54675476, time: [5.06], best model: 1\n",
      "Epoch: 5, train_loss: 0.50689939, valid_loss: 0.50335752, time: [5.06], best model: 1\n",
      "Epoch: 6, train_loss: 0.48867325, valid_loss: 0.4914403, time: [5.04], best model: 1\n",
      "Epoch: 7, train_loss: 0.45448486, valid_loss: 0.45092317, time: [4.98], best model: 1\n",
      "Epoch: 8, train_loss: 0.41945774, valid_loss: 0.44165238, time: [5.01], best model: 1\n",
      "Epoch: 9, train_loss: 0.40054558, valid_loss: 0.43026999, time: [4.95], best model: 1\n",
      "Epoch: 10, train_loss: 0.38690618, valid_loss: 0.42572707, time: [5.01], best model: 1\n",
      "Epoch: 11, train_loss: 0.36804898, valid_loss: 0.41417963, time: [5.01], best model: 1\n",
      "Epoch: 12, train_loss: 0.36300039, valid_loss: 0.40409832, time: [5.06], best model: 1\n",
      "Epoch: 13, train_loss: 0.33985587, valid_loss: 0.39837128, time: [4.98], best model: 1\n",
      "Epoch: 14, train_loss: 0.32761507, valid_loss: 0.3929586, time: [4.92], best model: 1\n",
      "Epoch: 15, train_loss: 0.31835226, valid_loss: 0.40136856, time: [4.97], best model: 0\n",
      "Epoch: 16, train_loss: 0.32532582, valid_loss: 0.37214943, time: [5.03], best model: 1\n",
      "Epoch: 17, train_loss: 0.31594822, valid_loss: 0.37427088, time: [5.03], best model: 0\n",
      "Epoch: 18, train_loss: 0.30628701, valid_loss: 0.37858063, time: [5.13], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "On sample 5 / 10 (hyperparams = {'cell_size': 59, 'hidden_size': 93, 'learning_rate': 0.06904675101784023, 'num_epochs': 72, 'patience': 5, 'batch_size': 52, 'early_stop_frac': 0.07804439920644052, 'seed': 649})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (rl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (hl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=93, bias=True)\n",
      "  (fc): Linear(in_features=93, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81109861, valid_loss: 0.83877662, time: [6.17], best model: 1\n",
      "Epoch: 1, train_loss: 0.71014494, valid_loss: 0.75754269, time: [6.02], best model: 1\n",
      "Epoch: 2, train_loss: 0.6220332, valid_loss: 0.67197414, time: [6.05], best model: 1\n",
      "Epoch: 3, train_loss: 0.57290964, valid_loss: 0.62544116, time: [6.03], best model: 1\n",
      "Epoch: 4, train_loss: 0.51506289, valid_loss: 0.56475574, time: [6.01], best model: 1\n",
      "Epoch: 5, train_loss: 0.46884972, valid_loss: 0.5390345, time: [6.03], best model: 1\n",
      "Epoch: 6, train_loss: 0.44111436, valid_loss: 0.52613521, time: [6.03], best model: 1\n",
      "Epoch: 7, train_loss: 0.42005579, valid_loss: 0.48556528, time: [6.08], best model: 1\n",
      "Epoch: 8, train_loss: 0.40034768, valid_loss: 0.45752496, time: [6.18], best model: 1\n",
      "Epoch: 9, train_loss: 0.38037886, valid_loss: 0.43686411, time: [6.43], best model: 1\n",
      "Epoch: 10, train_loss: 0.3501803, valid_loss: 0.41053745, time: [6.31], best model: 1\n",
      "Epoch: 11, train_loss: 0.34417422, valid_loss: 0.39806855, time: [6.18], best model: 1\n",
      "Epoch: 12, train_loss: 0.32608158, valid_loss: 0.39147918, time: [6.23], best model: 1\n",
      "Epoch: 13, train_loss: 0.31816263, valid_loss: 0.38126957, time: [6.47], best model: 1\n",
      "Epoch: 14, train_loss: 0.30992723, valid_loss: 0.36764073, time: [6.36], best model: 1\n",
      "Epoch: 15, train_loss: 0.3033412, valid_loss: 0.35482075, time: [6.08], best model: 1\n",
      "Epoch: 16, train_loss: 0.30027937, valid_loss: 0.37245396, time: [6.11], best model: 0\n",
      "Epoch: 17, train_loss: 0.28919846, valid_loss: 0.36953002, time: [6.19], best model: 0\n",
      "Epoch: 18, train_loss: 0.28948669, valid_loss: 0.35327193, time: [6.19], best model: 1\n",
      "Epoch: 19, train_loss: 0.28422102, valid_loss: 0.3474606, time: [6.15], best model: 1\n",
      "Epoch: 20, train_loss: 0.27390938, valid_loss: 0.33266, time: [6.29], best model: 1\n",
      "Epoch: 21, train_loss: 0.27089431, valid_loss: 0.34838602, time: [6.21], best model: 0\n",
      "Epoch: 22, train_loss: 0.25934634, valid_loss: 0.33129091, time: [6.43], best model: 1\n",
      "Epoch: 23, train_loss: 0.26064758, valid_loss: 0.35834876, time: [6.31], best model: 0\n",
      "Epoch: 24, train_loss: 0.26370764, valid_loss: 0.34247504, time: [6.15], best model: 0\n",
      "Epoch: 25, train_loss: 0.2403183, valid_loss: 0.35029494, time: [6.45], best model: 0\n",
      "Epoch: 26, train_loss: 0.24764943, valid_loss: 0.34889513, time: [6.2], best model: 0\n",
      "Early Stopped at Epoch: 27\n",
      "On sample 6 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 71, 'learning_rate': 0.0437304802367127, 'num_epochs': 16, 'patience': 6, 'batch_size': 46, 'early_stop_frac': 0.12892793284514886, 'seed': 9505})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (rl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (hl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=71, bias=True)\n",
      "  (fc): Linear(in_features=71, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.82866073, valid_loss: 0.85520357, time: [5.22], best model: 1\n",
      "Epoch: 1, train_loss: 0.68800044, valid_loss: 0.72955523, time: [5.16], best model: 1\n",
      "Epoch: 2, train_loss: 0.64834029, valid_loss: 0.66465537, time: [5.16], best model: 1\n",
      "Epoch: 3, train_loss: 0.56555226, valid_loss: 0.58661396, time: [5.24], best model: 1\n",
      "Epoch: 4, train_loss: 0.51047813, valid_loss: 0.54995283, time: [5.25], best model: 1\n",
      "Epoch: 5, train_loss: 0.46185143, valid_loss: 0.50877565, time: [5.21], best model: 1\n",
      "Epoch: 6, train_loss: 0.43968536, valid_loss: 0.49004414, time: [5.25], best model: 1\n",
      "Epoch: 7, train_loss: 0.41967987, valid_loss: 0.44855659, time: [5.37], best model: 1\n",
      "Epoch: 8, train_loss: 0.38352916, valid_loss: 0.43883758, time: [5.31], best model: 1\n",
      "Epoch: 9, train_loss: 0.36059159, valid_loss: 0.41309189, time: [5.35], best model: 1\n",
      "Epoch: 10, train_loss: 0.3544667, valid_loss: 0.38617597, time: [5.29], best model: 1\n",
      "Epoch: 11, train_loss: 0.34290037, valid_loss: 0.37315972, time: [5.28], best model: 1\n",
      "Epoch: 12, train_loss: 0.32764232, valid_loss: 0.36514299, time: [5.42], best model: 1\n",
      "Epoch: 13, train_loss: 0.31517482, valid_loss: 0.36736935, time: [5.45], best model: 0\n",
      "Epoch: 14, train_loss: 0.30324422, valid_loss: 0.36331986, time: [5.44], best model: 1\n",
      "Epoch: 15, train_loss: 0.30495736, valid_loss: 0.37205459, time: [5.35], best model: 0\n",
      "New Best Score: 82.84 @ hyperparams = {'cell_size': 61, 'hidden_size': 71, 'learning_rate': 0.0437304802367127, 'num_epochs': 16, 'patience': 6, 'batch_size': 46, 'early_stop_frac': 0.12892793284514886, 'seed': 9505}\n",
      "On sample 7 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 90, 'learning_rate': 0.05786898284457517, 'num_epochs': 143, 'patience': 6, 'batch_size': 47, 'early_stop_frac': 0.06032260065776421, 'seed': 7587})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (rl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (hl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=90, bias=True)\n",
      "  (fc): Linear(in_features=90, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81689095, valid_loss: 0.83415, time: [6.6], best model: 1\n",
      "Epoch: 1, train_loss: 0.71244637, valid_loss: 0.69632395, time: [6.54], best model: 1\n",
      "Epoch: 2, train_loss: 0.61952511, valid_loss: 0.62950102, time: [6.43], best model: 1\n",
      "Epoch: 3, train_loss: 0.54592069, valid_loss: 0.55705178, time: [6.44], best model: 1\n",
      "Epoch: 4, train_loss: 0.48941048, valid_loss: 0.53029112, time: [6.35], best model: 1\n",
      "Epoch: 5, train_loss: 0.45777345, valid_loss: 0.48700074, time: [6.35], best model: 1\n",
      "Epoch: 6, train_loss: 0.43461835, valid_loss: 0.45050033, time: [6.46], best model: 1\n",
      "Epoch: 7, train_loss: 0.39557556, valid_loss: 0.4245375, time: [6.58], best model: 1\n",
      "Epoch: 8, train_loss: 0.37431661, valid_loss: 0.42005889, time: [6.67], best model: 1\n",
      "Epoch: 9, train_loss: 0.36814682, valid_loss: 0.39464275, time: [6.54], best model: 1\n",
      "Epoch: 10, train_loss: 0.34502824, valid_loss: 0.3778284, time: [6.44], best model: 1\n",
      "Epoch: 11, train_loss: 0.33231801, valid_loss: 0.36703885, time: [6.76], best model: 1\n",
      "Epoch: 12, train_loss: 0.32031455, valid_loss: 0.34724939, time: [6.79], best model: 1\n",
      "Epoch: 13, train_loss: 0.30170814, valid_loss: 0.35408274, time: [6.64], best model: 0\n",
      "Epoch: 14, train_loss: 0.30758075, valid_loss: 0.3611695, time: [6.78], best model: 0\n",
      "Epoch: 15, train_loss: 0.29912466, valid_loss: 0.35829159, time: [6.5], best model: 0\n",
      "Epoch: 16, train_loss: 0.29174813, valid_loss: 0.34593201, time: [6.44], best model: 1\n",
      "Epoch: 17, train_loss: 0.27988042, valid_loss: 0.34273616, time: [6.43], best model: 1\n",
      "Epoch: 18, train_loss: 0.27967181, valid_loss: 0.33576496, time: [6.46], best model: 1\n",
      "Epoch: 19, train_loss: 0.26657401, valid_loss: 0.34938951, time: [6.49], best model: 0\n",
      "Epoch: 20, train_loss: 0.26188544, valid_loss: 0.34945246, time: [6.5], best model: 0\n",
      "Epoch: 21, train_loss: 0.26124636, valid_loss: 0.36821485, time: [6.45], best model: 0\n",
      "Epoch: 22, train_loss: 0.25728321, valid_loss: 0.34980329, time: [6.51], best model: 0\n",
      "Epoch: 23, train_loss: 0.25124462, valid_loss: 0.34275564, time: [6.49], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 8 / 10 (hyperparams = {'cell_size': 65, 'hidden_size': 83, 'learning_rate': 0.016038693859523376, 'num_epochs': 75, 'patience': 5, 'batch_size': 61, 'early_stop_frac': 0.09478935261759053, 'seed': 1680})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (rl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (hl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=83, bias=True)\n",
      "  (fc): Linear(in_features=83, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.82525715, valid_loss: 0.83629103, time: [5.41], best model: 1\n",
      "Epoch: 1, train_loss: 0.72785649, valid_loss: 0.7460858, time: [5.41], best model: 1\n",
      "Epoch: 2, train_loss: 0.65367605, valid_loss: 0.67348045, time: [5.33], best model: 1\n",
      "Epoch: 3, train_loss: 0.59191712, valid_loss: 0.62669647, time: [5.3], best model: 1\n",
      "Epoch: 4, train_loss: 0.5483161, valid_loss: 0.58973898, time: [5.47], best model: 1\n",
      "Epoch: 5, train_loss: 0.49218073, valid_loss: 0.5412379, time: [5.41], best model: 1\n",
      "Epoch: 6, train_loss: 0.47702134, valid_loss: 0.49985246, time: [5.41], best model: 1\n",
      "Epoch: 7, train_loss: 0.43219561, valid_loss: 0.48009426, time: [5.35], best model: 1\n",
      "Epoch: 8, train_loss: 0.41570215, valid_loss: 0.4675416, time: [5.34], best model: 1\n",
      "Epoch: 9, train_loss: 0.3904251, valid_loss: 0.43314182, time: [5.42], best model: 1\n",
      "Epoch: 10, train_loss: 0.36629166, valid_loss: 0.42466188, time: [5.28], best model: 1\n",
      "Epoch: 11, train_loss: 0.36005831, valid_loss: 0.42535465, time: [5.44], best model: 0\n",
      "Epoch: 12, train_loss: 0.34868359, valid_loss: 0.40033719, time: [5.62], best model: 1\n",
      "Epoch: 13, train_loss: 0.33912342, valid_loss: 0.40899105, time: [5.38], best model: 0\n",
      "Epoch: 14, train_loss: 0.32257201, valid_loss: 0.39121759, time: [5.39], best model: 1\n",
      "Epoch: 15, train_loss: 0.31748847, valid_loss: 0.38735454, time: [5.57], best model: 1\n",
      "Epoch: 16, train_loss: 0.31052829, valid_loss: 0.38483464, time: [5.5], best model: 1\n",
      "Epoch: 17, train_loss: 0.30240276, valid_loss: 0.38168695, time: [5.38], best model: 1\n",
      "Epoch: 18, train_loss: 0.29733029, valid_loss: 0.38097956, time: [5.36], best model: 1\n",
      "Epoch: 19, train_loss: 0.28683942, valid_loss: 0.35911364, time: [5.28], best model: 1\n",
      "Epoch: 20, train_loss: 0.2842599, valid_loss: 0.36563927, time: [5.51], best model: 0\n",
      "Epoch: 21, train_loss: 0.27622771, valid_loss: 0.35721032, time: [5.5], best model: 1\n",
      "Epoch: 22, train_loss: 0.27757333, valid_loss: 0.36935304, time: [5.38], best model: 0\n",
      "Epoch: 23, train_loss: 0.26901065, valid_loss: 0.36854161, time: [5.5], best model: 0\n",
      "Epoch: 24, train_loss: 0.25851341, valid_loss: 0.36364652, time: [5.76], best model: 0\n",
      "Epoch: 25, train_loss: 0.2509317, valid_loss: 0.3655507, time: [5.69], best model: 0\n",
      "Early Stopped at Epoch: 26\n",
      "On sample 9 / 10 (hyperparams = {'cell_size': 50, 'hidden_size': 85, 'learning_rate': 0.021810148908487884, 'num_epochs': 23, 'patience': 4, 'batch_size': 55, 'early_stop_frac': 0.14085955030930958, 'seed': 7256})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (rl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (hl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=85, bias=True)\n",
      "  (fc): Linear(in_features=85, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83784383, valid_loss: 0.86072154, time: [5.43], best model: 1\n",
      "Epoch: 1, train_loss: 0.72658346, valid_loss: 0.71054977, time: [5.39], best model: 1\n",
      "Epoch: 2, train_loss: 0.64754613, valid_loss: 0.68277023, time: [5.45], best model: 1\n",
      "Epoch: 3, train_loss: 0.58676737, valid_loss: 0.63857524, time: [5.38], best model: 1\n",
      "Epoch: 4, train_loss: 0.54827352, valid_loss: 0.56921519, time: [5.35], best model: 1\n",
      "Epoch: 5, train_loss: 0.48257619, valid_loss: 0.53190557, time: [5.38], best model: 1\n",
      "Epoch: 6, train_loss: 0.44111394, valid_loss: 0.50678024, time: [5.32], best model: 1\n",
      "Epoch: 7, train_loss: 0.4356634, valid_loss: 0.49497345, time: [5.3], best model: 1\n",
      "Epoch: 8, train_loss: 0.41317952, valid_loss: 0.49168986, time: [5.35], best model: 1\n",
      "Epoch: 9, train_loss: 0.37601603, valid_loss: 0.48350464, time: [5.38], best model: 1\n",
      "Epoch: 10, train_loss: 0.36275419, valid_loss: 0.47832179, time: [5.35], best model: 1\n",
      "Epoch: 11, train_loss: 0.35910212, valid_loss: 0.452453, time: [5.42], best model: 1\n",
      "Epoch: 12, train_loss: 0.33847801, valid_loss: 0.43583359, time: [5.42], best model: 1\n",
      "Epoch: 13, train_loss: 0.32687902, valid_loss: 0.42364749, time: [5.4], best model: 1\n",
      "Epoch: 14, train_loss: 0.32256045, valid_loss: 0.42475932, time: [5.3], best model: 0\n",
      "Epoch: 15, train_loss: 0.32168566, valid_loss: 0.42766886, time: [5.34], best model: 0\n",
      "Epoch: 16, train_loss: 0.30516708, valid_loss: 0.42233966, time: [5.25], best model: 1\n",
      "Epoch: 17, train_loss: 0.31068044, valid_loss: 0.42067869, time: [5.37], best model: 1\n",
      "Epoch: 18, train_loss: 0.29871574, valid_loss: 0.41939196, time: [5.42], best model: 1\n",
      "Epoch: 19, train_loss: 0.28952021, valid_loss: 0.408355, time: [5.4], best model: 1\n",
      "Epoch: 20, train_loss: 0.27669792, valid_loss: 0.41142365, time: [5.36], best model: 0\n",
      "Epoch: 21, train_loss: 0.27747276, valid_loss: 0.41511024, time: [5.52], best model: 0\n",
      "Epoch: 22, train_loss: 0.28183578, valid_loss: 0.42424929, time: [5.63], best model: 0\n",
      "On sample 10 / 10 (hyperparams = {'cell_size': 66, 'hidden_size': 70, 'learning_rate': 0.08207445686755367, 'num_epochs': 130, 'patience': 4, 'batch_size': 51, 'early_stop_frac': 0.07936141483736796, 'seed': 7962})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (rl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (hl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=70, bias=True)\n",
      "  (fc): Linear(in_features=70, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.82433958, valid_loss: 0.82074817, time: [5.27], best model: 1\n",
      "Epoch: 1, train_loss: 0.70785518, valid_loss: 0.72600649, time: [5.27], best model: 1\n",
      "Epoch: 2, train_loss: 0.63754135, valid_loss: 0.66989646, time: [5.26], best model: 1\n",
      "Epoch: 3, train_loss: 0.57344481, valid_loss: 0.60002256, time: [5.17], best model: 1\n",
      "Epoch: 4, train_loss: 0.51546132, valid_loss: 0.55774019, time: [5.28], best model: 1\n",
      "Epoch: 5, train_loss: 0.48028187, valid_loss: 0.53039285, time: [5.22], best model: 1\n",
      "Epoch: 6, train_loss: 0.43740423, valid_loss: 0.49036838, time: [5.19], best model: 1\n",
      "Epoch: 7, train_loss: 0.39810305, valid_loss: 0.46369992, time: [5.13], best model: 1\n",
      "Epoch: 8, train_loss: 0.38487346, valid_loss: 0.45750755, time: [5.14], best model: 1\n",
      "Epoch: 9, train_loss: 0.36437412, valid_loss: 0.43882849, time: [5.31], best model: 1\n",
      "Epoch: 10, train_loss: 0.36315503, valid_loss: 0.42009407, time: [5.39], best model: 1\n",
      "Epoch: 11, train_loss: 0.343951, valid_loss: 0.41652932, time: [5.23], best model: 1\n",
      "Epoch: 12, train_loss: 0.33689987, valid_loss: 0.399696, time: [5.24], best model: 1\n",
      "Epoch: 13, train_loss: 0.32454171, valid_loss: 0.40283035, time: [5.32], best model: 0\n",
      "Epoch: 14, train_loss: 0.31286408, valid_loss: 0.38825377, time: [5.23], best model: 1\n",
      "Epoch: 15, train_loss: 0.30696873, valid_loss: 0.39628419, time: [5.23], best model: 0\n",
      "Epoch: 16, train_loss: 0.29576277, valid_loss: 0.39232192, time: [5.24], best model: 0\n",
      "Epoch: 17, train_loss: 0.28867879, valid_loss: 0.39040561, time: [5.14], best model: 0\n",
      "Epoch: 18, train_loss: 0.28773388, valid_loss: 0.38099852, time: [5.14], best model: 1\n",
      "Epoch: 19, train_loss: 0.28410896, valid_loss: 0.38435342, time: [5.14], best model: 0\n",
      "Epoch: 20, train_loss: 0.27401687, valid_loss: 0.39556787, time: [5.14], best model: 0\n",
      "Epoch: 21, train_loss: 0.2757681, valid_loss: 0.38915235, time: [5.13], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "New Best Score: 83.52 @ hyperparams = {'cell_size': 66, 'hidden_size': 70, 'learning_rate': 0.08207445686755367, 'num_epochs': 130, 'patience': 4, 'batch_size': 51, 'early_stop_frac': 0.07936141483736796, 'seed': 7962}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (rl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (hl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=70, bias=True)\n",
      "  (fc): Linear(in_features=70, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.8263754, valid_loss: 0.85246516, time: [5.96], best model: 1\n",
      "Epoch: 1, train_loss: 0.70505015, valid_loss: 0.71953167, time: [6.08], best model: 1\n",
      "Epoch: 2, train_loss: 0.62029894, valid_loss: 0.63190479, time: [6.1], best model: 1\n",
      "Epoch: 3, train_loss: 0.5579735, valid_loss: 0.57665468, time: [6.03], best model: 1\n",
      "Epoch: 4, train_loss: 0.50096204, valid_loss: 0.50709988, time: [5.96], best model: 1\n",
      "Epoch: 5, train_loss: 0.44388083, valid_loss: 0.47756276, time: [5.92], best model: 1\n",
      "Epoch: 6, train_loss: 0.41713915, valid_loss: 0.44507541, time: [5.99], best model: 1\n",
      "Epoch: 7, train_loss: 0.39021163, valid_loss: 0.42174931, time: [6.02], best model: 1\n",
      "Epoch: 8, train_loss: 0.37417021, valid_loss: 0.39401619, time: [6.02], best model: 1\n",
      "Epoch: 9, train_loss: 0.35658515, valid_loss: 0.40867091, time: [6.02], best model: 0\n",
      "Epoch: 10, train_loss: 0.34504095, valid_loss: 0.38397329, time: [5.92], best model: 1\n",
      "Epoch: 11, train_loss: 0.32685016, valid_loss: 0.38322291, time: [5.91], best model: 1\n",
      "Epoch: 12, train_loss: 0.3187188, valid_loss: 0.36903705, time: [5.93], best model: 1\n",
      "Epoch: 13, train_loss: 0.3125063, valid_loss: 0.36039684, time: [5.92], best model: 1\n",
      "Epoch: 14, train_loss: 0.30389998, valid_loss: 0.36690602, time: [5.99], best model: 0\n",
      "Epoch: 15, train_loss: 0.28865051, valid_loss: 0.35964835, time: [6.04], best model: 1\n",
      "Epoch: 16, train_loss: 0.28801041, valid_loss: 0.37136675, time: [6.04], best model: 0\n",
      "Epoch: 17, train_loss: 0.28835536, valid_loss: 0.37596412, time: [6.03], best model: 0\n",
      "Epoch: 18, train_loss: 0.2820561, valid_loss: 0.37104782, time: [5.91], best model: 0\n",
      "Epoch: 19, train_loss: 0.26422938, valid_loss: 0.35960315, time: [5.98], best model: 1\n",
      "Epoch: 20, train_loss: 0.26811451, valid_loss: 0.37607162, time: [5.99], best model: 0\n",
      "Epoch: 21, train_loss: 0.2628106, valid_loss: 0.38363493, time: [5.91], best model: 0\n",
      "Epoch: 22, train_loss: 0.24948378, valid_loss: 0.37867779, time: [5.92], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "CPU times: user 23min 4s, sys: 38.7 s, total: 23min 43s\n",
      "Wall time: 23min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "results = {}\n",
    "if model_name not in results: results[model_name] = {}\n",
    "for t in [\n",
    "    'mort_icu',\n",
    "#    'los_3',\n",
    "#    'mort_hosp',\n",
    "#    'los_7'\n",
    "]:\n",
    "    if t not in results[model_name]: results[model_name][t] = {}\n",
    "    for n, X_train, X_dev, X_test in (\n",
    "        ('lvl2', lvl2_train, lvl2_dev, lvl2_test),\n",
    "#         ('raw', raw_train, raw_dev, raw_test)\n",
    "    ):\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        X_mean = np.nanmean(\n",
    "            to_3D_tensor(\n",
    "                X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "                np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "            ),\n",
    "            axis=0, keepdims=True\n",
    "        ).transpose([0, 2, 1])\n",
    "        base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "    \n",
    "        if n in results[model_name][t]:\n",
    "            if not RERUN: \n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                print(results[model_name][t][n])\n",
    "                continue\n",
    "            best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "            print(\"Loading best hyperparams\", best_hyperparams)\n",
    "        else:\n",
    "            best_s, best_hyperparams = -np.Inf, None\n",
    "            for i, hyperparams in enumerate(hyperparams_list):\n",
    "                print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "                early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "                batch_size = int(batch_size)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                all_train_subjects = list(\n",
    "                    np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "                )\n",
    "                N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "                train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "                early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "                X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "                Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "                X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "                Ys_train_early_stop = Ys_train[\n",
    "                    Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "                ]\n",
    "\n",
    "                train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "                early_stop_dataloader = prepare_dataloader(\n",
    "                    X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size\n",
    "                )\n",
    "                dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=batch_size)\n",
    "                test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "                model_hyperparams = copy.copy(base_params)\n",
    "                model_hyperparams.update(\n",
    "                    {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "                )\n",
    "                \n",
    "                batch_size = int(batch_size)\n",
    "                model = GRUD(**model_hyperparams)\n",
    "\n",
    "                best_model, _ = Train_Model(\n",
    "                    model, train_dataloader, early_stop_dataloader,\n",
    "                    **{k: v for k, v in hyperparams.items() if k in (\n",
    "                        'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                    )}\n",
    "                )\n",
    "\n",
    "                probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "                probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "                labels_dev        = np.concatenate(labels_dev)\n",
    "                s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "                if s > best_s:\n",
    "                    best_s, best_hyperparams = s, hyperparams\n",
    "                    print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "        ## Test\n",
    "        try:\n",
    "            np.random.seed(seed)\n",
    "            hyperparams = best_hyperparams # In case I forgot a replace below\n",
    "            early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "            batch_size = int(batch_size)\n",
    "            X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "\n",
    "            all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "            N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "            train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "            X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "            Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "            X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "            Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "            train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "            early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "            test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "            model_hyperparams = copy.copy(base_params)\n",
    "            model_hyperparams.update(\n",
    "                {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "            )\n",
    "            model = GRUD(**model_hyperparams)\n",
    "\n",
    "            best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "                model, train_dataloader, early_stop_dataloader,\n",
    "                **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "                    'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                )}\n",
    "            )\n",
    "\n",
    "            probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "            y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "            y_pred  = np.argmax(probabilities_test)\n",
    "            y_true  = np.concatenate(labels_test)\n",
    "\n",
    "            auc   = roc_auc_score(y_true, y_score)\n",
    "            auprc = average_precision_score(y_true, y_score)\n",
    "            acc   = accuracy_score(y_true, y_pred)\n",
    "            F1    = f1_score(y_true, y_pred)\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(auc, auprc, acc, F1)\n",
    "\n",
    "            results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "            #with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)\n",
    "        except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results for model GRU-D on target mort_icu with representation lvl2\n",
      "0.8000927930714506 0.49750594932299874 0.9336349924585219 0.5217391304347827\n"
     ]
    }
   ],
   "source": [
    "y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "y_true  = np.concatenate(labels_test)\n",
    "\n",
    "y_score  = np.nan_to_num(y_score , nan=0, posinf=0)\n",
    "y_pred  = np.nan_to_num(y_pred , nan=0, posinf=0)\n",
    "y_true  = np.nan_to_num(y_true , nan=0, posinf=0)\n",
    "\n",
    "auc   = roc_auc_score(y_true, y_score)\n",
    "auprc = average_precision_score(y_true, y_score)\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "F1    = f1_score(y_true, y_pred)\n",
    "print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "print(auc, auprc, acc, F1)\n",
    "\n",
    "results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "#with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target los_3 with representation lvl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
      "<timed exec>:17: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.7801476, valid_loss: 0.79148749, time: [4.85], best model: 1\n",
      "Epoch: 1, train_loss: 0.72961817, valid_loss: 0.69362465, time: [4.86], best model: 1\n",
      "Epoch: 2, train_loss: 0.68405769, valid_loss: 0.71215384, time: [4.83], best model: 0\n",
      "Epoch: 3, train_loss: 0.66397968, valid_loss: 0.70644409, time: [4.82], best model: 0\n",
      "Epoch: 4, train_loss: 0.65943683, valid_loss: 0.69757386, time: [4.91], best model: 0\n",
      "Epoch: 5, train_loss: 0.63232843, valid_loss: 0.67375038, time: [4.91], best model: 1\n",
      "Epoch: 6, train_loss: 0.62834956, valid_loss: 0.65725608, time: [4.93], best model: 1\n",
      "Epoch: 7, train_loss: 0.62246262, valid_loss: 0.66260408, time: [4.93], best model: 0\n",
      "Epoch: 8, train_loss: 0.60316071, valid_loss: 0.66253993, time: [4.94], best model: 0\n",
      "Epoch: 9, train_loss: 0.59433616, valid_loss: 0.66695183, time: [5.01], best model: 0\n",
      "Epoch: 10, train_loss: 0.5836928, valid_loss: 0.65930136, time: [4.96], best model: 0\n",
      "Epoch: 11, train_loss: 0.58693133, valid_loss: 0.67758831, time: [4.87], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "New Best Score: 69.41 @ hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496}\n",
      "On sample 2 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (rl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (hl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=77, bias=True)\n",
      "  (fc): Linear(in_features=77, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.80214913, valid_loss: 0.79616845, time: [5.97], best model: 1\n",
      "Epoch: 1, train_loss: 0.70641667, valid_loss: 0.750244, time: [5.94], best model: 1\n",
      "Epoch: 2, train_loss: 0.67261498, valid_loss: 0.72656659, time: [5.88], best model: 1\n",
      "Epoch: 3, train_loss: 0.65241304, valid_loss: 0.72756278, time: [5.86], best model: 0\n",
      "Epoch: 4, train_loss: 0.62889696, valid_loss: 0.71885716, time: [5.87], best model: 1\n",
      "Epoch: 5, train_loss: 0.62386849, valid_loss: 0.69800082, time: [5.86], best model: 1\n",
      "Epoch: 6, train_loss: 0.60437539, valid_loss: 0.6941916, time: [5.9], best model: 1\n",
      "Epoch: 7, train_loss: 0.60778947, valid_loss: 0.6967512, time: [5.87], best model: 0\n",
      "Epoch: 8, train_loss: 0.58417282, valid_loss: 0.6869495, time: [5.83], best model: 1\n",
      "Epoch: 9, train_loss: 0.5811031, valid_loss: 0.69680488, time: [5.84], best model: 0\n",
      "Epoch: 10, train_loss: 0.58232609, valid_loss: 0.70203837, time: [5.84], best model: 0\n",
      "Epoch: 11, train_loss: 0.56180472, valid_loss: 0.69047623, time: [5.87], best model: 0\n",
      "Epoch: 12, train_loss: 0.55818676, valid_loss: 0.71357588, time: [5.93], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "New Best Score: 70.17 @ hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429}\n",
      "On sample 3 / 10 (hyperparams = {'cell_size': 62, 'hidden_size': 72, 'learning_rate': 0.08981174363909455, 'num_epochs': 76, 'patience': 4, 'batch_size': 39, 'early_stop_frac': 0.14888610889064946, 'seed': 156})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (rl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (hl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=72, bias=True)\n",
      "  (fc): Linear(in_features=72, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78484344, valid_loss: 0.74333373, time: [5.52], best model: 1\n",
      "Epoch: 1, train_loss: 0.71712072, valid_loss: 0.69438164, time: [5.56], best model: 1\n",
      "Epoch: 2, train_loss: 0.68028855, valid_loss: 0.682728, time: [5.54], best model: 1\n",
      "Epoch: 3, train_loss: 0.66295522, valid_loss: 0.66573, time: [5.54], best model: 1\n",
      "Epoch: 4, train_loss: 0.66355533, valid_loss: 0.6573551, time: [5.4], best model: 1\n",
      "Epoch: 5, train_loss: 0.63046882, valid_loss: 0.65288544, time: [5.41], best model: 1\n",
      "Epoch: 6, train_loss: 0.61507445, valid_loss: 0.64138031, time: [5.4], best model: 1\n",
      "Epoch: 7, train_loss: 0.61570013, valid_loss: 0.64532304, time: [5.41], best model: 0\n",
      "Epoch: 8, train_loss: 0.6031383, valid_loss: 0.64813567, time: [5.41], best model: 0\n",
      "Epoch: 9, train_loss: 0.57180888, valid_loss: 0.64636354, time: [5.4], best model: 0\n",
      "Early Stopped at Epoch: 10\n",
      "New Best Score: 70.52 @ hyperparams = {'cell_size': 62, 'hidden_size': 72, 'learning_rate': 0.08981174363909455, 'num_epochs': 76, 'patience': 4, 'batch_size': 39, 'early_stop_frac': 0.14888610889064946, 'seed': 156}\n",
      "On sample 4 / 10 (hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (rl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (hl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=78, bias=True)\n",
      "  (fc): Linear(in_features=78, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83186335, valid_loss: 0.79943498, time: [4.93], best model: 1\n",
      "Epoch: 1, train_loss: 0.71761945, valid_loss: 0.73359847, time: [4.92], best model: 1\n",
      "Epoch: 2, train_loss: 0.68284166, valid_loss: 0.72042847, time: [4.92], best model: 1\n",
      "Epoch: 3, train_loss: 0.67089376, valid_loss: 0.70255339, time: [5.16], best model: 1\n",
      "Epoch: 4, train_loss: 0.65827926, valid_loss: 0.68157599, time: [4.99], best model: 1\n",
      "Epoch: 5, train_loss: 0.6268987, valid_loss: 0.6654799, time: [4.95], best model: 1\n",
      "Epoch: 6, train_loss: 0.62453009, valid_loss: 0.69887795, time: [4.93], best model: 0\n",
      "Epoch: 7, train_loss: 0.61006842, valid_loss: 0.6787587, time: [5.13], best model: 0\n",
      "Epoch: 8, train_loss: 0.5981707, valid_loss: 0.65326062, time: [5.15], best model: 1\n",
      "Epoch: 9, train_loss: 0.58797756, valid_loss: 0.67004518, time: [5.28], best model: 0\n",
      "Epoch: 10, train_loss: 0.57940803, valid_loss: 0.68234817, time: [5.34], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "New Best Score: 70.90 @ hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410}\n",
      "On sample 5 / 10 (hyperparams = {'cell_size': 59, 'hidden_size': 93, 'learning_rate': 0.06904675101784023, 'num_epochs': 72, 'patience': 5, 'batch_size': 52, 'early_stop_frac': 0.07804439920644052, 'seed': 649})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (rl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (hl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=93, bias=True)\n",
      "  (fc): Linear(in_features=93, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78226202, valid_loss: 0.79080092, time: [6.11], best model: 1\n",
      "Epoch: 1, train_loss: 0.71331931, valid_loss: 0.72127668, time: [6.09], best model: 1\n",
      "Epoch: 2, train_loss: 0.68776447, valid_loss: 0.69748459, time: [6.12], best model: 1\n",
      "Epoch: 3, train_loss: 0.66820374, valid_loss: 0.69910826, time: [6.13], best model: 0\n",
      "Epoch: 4, train_loss: 0.63748667, valid_loss: 0.68547058, time: [6.17], best model: 1\n",
      "Epoch: 5, train_loss: 0.63751315, valid_loss: 0.66753253, time: [6.13], best model: 1\n",
      "Epoch: 6, train_loss: 0.6060182, valid_loss: 0.66429515, time: [6.14], best model: 1\n",
      "Epoch: 7, train_loss: 0.60746236, valid_loss: 0.65413711, time: [6.37], best model: 1\n",
      "Epoch: 8, train_loss: 0.59967966, valid_loss: 0.65327938, time: [6.29], best model: 1\n",
      "Epoch: 9, train_loss: 0.58877842, valid_loss: 0.66922073, time: [6.27], best model: 0\n",
      "Epoch: 10, train_loss: 0.57773123, valid_loss: 0.65932083, time: [6.12], best model: 0\n",
      "Epoch: 11, train_loss: 0.5651728, valid_loss: 0.66847543, time: [6.07], best model: 0\n",
      "Epoch: 12, train_loss: 0.55347775, valid_loss: 0.66651338, time: [6.1], best model: 0\n",
      "Early Stopped at Epoch: 13\n",
      "On sample 6 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 71, 'learning_rate': 0.0437304802367127, 'num_epochs': 16, 'patience': 6, 'batch_size': 46, 'early_stop_frac': 0.12892793284514886, 'seed': 9505})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (rl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (hl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=71, bias=True)\n",
      "  (fc): Linear(in_features=71, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.79182233, valid_loss: 0.7779038, time: [5.31], best model: 1\n",
      "Epoch: 1, train_loss: 0.73582962, valid_loss: 0.70133239, time: [5.28], best model: 1\n",
      "Epoch: 2, train_loss: 0.68604136, valid_loss: 0.69388182, time: [5.2], best model: 1\n",
      "Epoch: 3, train_loss: 0.68440251, valid_loss: 0.6864663, time: [5.21], best model: 1\n",
      "Epoch: 4, train_loss: 0.65120316, valid_loss: 0.68822098, time: [5.21], best model: 0\n",
      "Epoch: 5, train_loss: 0.63120475, valid_loss: 0.68245211, time: [5.25], best model: 1\n",
      "Epoch: 6, train_loss: 0.62784878, valid_loss: 0.65712864, time: [5.24], best model: 1\n",
      "Epoch: 7, train_loss: 0.61797894, valid_loss: 0.6596429, time: [5.22], best model: 0\n",
      "Epoch: 8, train_loss: 0.59560654, valid_loss: 0.65442796, time: [5.22], best model: 1\n",
      "Epoch: 9, train_loss: 0.59261024, valid_loss: 0.66227588, time: [5.23], best model: 0\n",
      "Epoch: 10, train_loss: 0.58066609, valid_loss: 0.6479859, time: [5.22], best model: 1\n",
      "Epoch: 11, train_loss: 0.569526, valid_loss: 0.65197469, time: [5.23], best model: 0\n",
      "Epoch: 12, train_loss: 0.56589722, valid_loss: 0.66177142, time: [5.22], best model: 0\n",
      "Epoch: 13, train_loss: 0.5535503, valid_loss: 0.67294542, time: [5.24], best model: 0\n",
      "Epoch: 14, train_loss: 0.53724302, valid_loss: 0.68895009, time: [5.22], best model: 0\n",
      "Epoch: 15, train_loss: 0.53031339, valid_loss: 0.67647263, time: [5.24], best model: 0\n",
      "On sample 7 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 90, 'learning_rate': 0.05786898284457517, 'num_epochs': 143, 'patience': 6, 'batch_size': 47, 'early_stop_frac': 0.06032260065776421, 'seed': 7587})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (rl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (hl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=90, bias=True)\n",
      "  (fc): Linear(in_features=90, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.77865171, valid_loss: 0.79531105, time: [6.32], best model: 1\n",
      "Epoch: 1, train_loss: 0.7047557, valid_loss: 0.77140458, time: [6.31], best model: 1\n",
      "Epoch: 2, train_loss: 0.67022753, valid_loss: 0.72471444, time: [6.31], best model: 1\n",
      "Epoch: 3, train_loss: 0.66293772, valid_loss: 0.72572382, time: [6.3], best model: 0\n",
      "Epoch: 4, train_loss: 0.64109075, valid_loss: 0.69427792, time: [6.3], best model: 1\n",
      "Epoch: 5, train_loss: 0.62751877, valid_loss: 0.70876924, time: [6.31], best model: 0\n",
      "Epoch: 6, train_loss: 0.61358448, valid_loss: 0.69259206, time: [6.34], best model: 1\n",
      "Epoch: 7, train_loss: 0.59689999, valid_loss: 0.68805496, time: [6.38], best model: 1\n",
      "Epoch: 8, train_loss: 0.58524366, valid_loss: 0.69090239, time: [6.49], best model: 0\n",
      "Epoch: 9, train_loss: 0.5741111, valid_loss: 0.68370358, time: [201.45], best model: 1\n",
      "Epoch: 10, train_loss: 0.55630835, valid_loss: 0.69666855, time: [6.46], best model: 0\n",
      "Epoch: 11, train_loss: 0.54570512, valid_loss: 0.68963194, time: [6.58], best model: 0\n",
      "Epoch: 12, train_loss: 0.54101825, valid_loss: 0.70724026, time: [6.78], best model: 0\n",
      "Epoch: 13, train_loss: 0.52718417, valid_loss: 0.74820932, time: [6.41], best model: 0\n",
      "Epoch: 14, train_loss: 0.5111262, valid_loss: 0.75142439, time: [6.41], best model: 0\n",
      "Early Stopped at Epoch: 15\n",
      "On sample 8 / 10 (hyperparams = {'cell_size': 65, 'hidden_size': 83, 'learning_rate': 0.016038693859523376, 'num_epochs': 75, 'patience': 5, 'batch_size': 61, 'early_stop_frac': 0.09478935261759053, 'seed': 1680})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (rl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (hl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=83, bias=True)\n",
      "  (fc): Linear(in_features=83, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.80384553, valid_loss: 0.76389651, time: [5.34], best model: 1\n",
      "Epoch: 1, train_loss: 0.71270725, valid_loss: 0.7049402, time: [5.34], best model: 1\n",
      "Epoch: 2, train_loss: 0.68563832, valid_loss: 0.72599508, time: [5.33], best model: 0\n",
      "Epoch: 3, train_loss: 0.66169921, valid_loss: 0.6959812, time: [5.34], best model: 1\n",
      "Epoch: 4, train_loss: 0.64455392, valid_loss: 0.68483562, time: [5.34], best model: 1\n",
      "Epoch: 5, train_loss: 0.64133899, valid_loss: 0.67064903, time: [5.34], best model: 1\n",
      "Epoch: 6, train_loss: 0.62265772, valid_loss: 0.65816122, time: [5.34], best model: 1\n",
      "Epoch: 7, train_loss: 0.61256479, valid_loss: 0.64882047, time: [5.34], best model: 1\n",
      "Epoch: 8, train_loss: 0.60951765, valid_loss: 0.64515047, time: [5.37], best model: 1\n",
      "Epoch: 9, train_loss: 0.60180804, valid_loss: 0.63358259, time: [5.36], best model: 1\n",
      "Epoch: 10, train_loss: 0.58084397, valid_loss: 0.65365568, time: [5.35], best model: 0\n",
      "Epoch: 11, train_loss: 0.58122914, valid_loss: 0.6544745, time: [5.36], best model: 0\n",
      "Epoch: 12, train_loss: 0.56294895, valid_loss: 0.65950082, time: [5.37], best model: 0\n",
      "Epoch: 13, train_loss: 0.55397093, valid_loss: 0.67803891, time: [5.37], best model: 0\n",
      "Early Stopped at Epoch: 14\n",
      "On sample 9 / 10 (hyperparams = {'cell_size': 50, 'hidden_size': 85, 'learning_rate': 0.021810148908487884, 'num_epochs': 23, 'patience': 4, 'batch_size': 55, 'early_stop_frac': 0.14085955030930958, 'seed': 7256})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (rl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (hl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=85, bias=True)\n",
      "  (fc): Linear(in_features=85, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.7972761, valid_loss: 0.77739044, time: [5.37], best model: 1\n",
      "Epoch: 1, train_loss: 0.71415492, valid_loss: 0.74521673, time: [5.36], best model: 1\n",
      "Epoch: 2, train_loss: 0.68596481, valid_loss: 0.73346268, time: [5.37], best model: 1\n",
      "Epoch: 3, train_loss: 0.66653188, valid_loss: 0.71381185, time: [5.39], best model: 1\n",
      "Epoch: 4, train_loss: 0.65617096, valid_loss: 0.69874751, time: [5.38], best model: 1\n",
      "Epoch: 5, train_loss: 0.63771306, valid_loss: 0.690684, time: [5.4], best model: 1\n",
      "Epoch: 6, train_loss: 0.62867055, valid_loss: 0.69050013, time: [5.4], best model: 1\n",
      "Epoch: 7, train_loss: 0.61026408, valid_loss: 0.66951492, time: [5.4], best model: 1\n",
      "Epoch: 8, train_loss: 0.59507411, valid_loss: 0.66320017, time: [5.42], best model: 1\n",
      "Epoch: 9, train_loss: 0.59119837, valid_loss: 0.66886882, time: [5.45], best model: 0\n",
      "Epoch: 10, train_loss: 0.57014206, valid_loss: 0.68118164, time: [5.45], best model: 0\n",
      "Epoch: 11, train_loss: 0.56023193, valid_loss: 0.69284027, time: [5.48], best model: 0\n",
      "Early Stopped at Epoch: 12\n",
      "On sample 10 / 10 (hyperparams = {'cell_size': 66, 'hidden_size': 70, 'learning_rate': 0.08207445686755367, 'num_epochs': 130, 'patience': 4, 'batch_size': 51, 'early_stop_frac': 0.07936141483736796, 'seed': 7962})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (rl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (hl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=70, bias=True)\n",
      "  (fc): Linear(in_features=70, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78710618, valid_loss: 0.80771743, time: [5.24], best model: 1\n",
      "Epoch: 1, train_loss: 0.71299442, valid_loss: 0.74734311, time: [5.24], best model: 1\n",
      "Epoch: 2, train_loss: 0.68680936, valid_loss: 0.72515625, time: [5.25], best model: 1\n",
      "Epoch: 3, train_loss: 0.66745337, valid_loss: 0.70148251, time: [5.25], best model: 1\n",
      "Epoch: 4, train_loss: 0.65130571, valid_loss: 0.7187673, time: [5.25], best model: 0\n",
      "Epoch: 5, train_loss: 0.64206354, valid_loss: 0.69236622, time: [5.26], best model: 1\n",
      "Epoch: 6, train_loss: 0.60639617, valid_loss: 0.68630471, time: [5.27], best model: 1\n",
      "Epoch: 7, train_loss: 0.60469925, valid_loss: 0.68902535, time: [5.25], best model: 0\n",
      "Epoch: 8, train_loss: 0.60384573, valid_loss: 0.66416297, time: [5.25], best model: 1\n",
      "Epoch: 9, train_loss: 0.58667768, valid_loss: 0.67386334, time: [5.24], best model: 0\n",
      "Epoch: 10, train_loss: 0.57383883, valid_loss: 0.68862542, time: [5.23], best model: 0\n",
      "Epoch: 11, train_loss: 0.56630175, valid_loss: 0.68471846, time: [5.22], best model: 0\n",
      "Early Stopped at Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (rl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (hl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=78, bias=True)\n",
      "  (fc): Linear(in_features=78, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81091111, valid_loss: 0.80550498, time: [5.75], best model: 1\n",
      "Epoch: 1, train_loss: 0.70704279, valid_loss: 0.74274261, time: [5.73], best model: 1\n",
      "Epoch: 2, train_loss: 0.67885896, valid_loss: 0.71880468, time: [5.73], best model: 1\n",
      "Epoch: 3, train_loss: 0.65182208, valid_loss: 0.71013933, time: [5.93], best model: 1\n",
      "Epoch: 4, train_loss: 0.64442915, valid_loss: 0.69019709, time: [5.71], best model: 1\n",
      "Epoch: 5, train_loss: 0.63645643, valid_loss: 0.67989712, time: [5.97], best model: 1\n",
      "Epoch: 6, train_loss: 0.61638919, valid_loss: 0.68884748, time: [5.88], best model: 0\n",
      "Epoch: 7, train_loss: 0.60305781, valid_loss: 0.67358761, time: [5.96], best model: 1\n",
      "Epoch: 8, train_loss: 0.59995326, valid_loss: 0.66194016, time: [5.75], best model: 1\n",
      "Epoch: 9, train_loss: 0.58441313, valid_loss: 0.67260398, time: [5.77], best model: 0\n",
      "Epoch: 10, train_loss: 0.57081623, valid_loss: 0.69064868, time: [5.74], best model: 0\n",
      "Early Stopped at Epoch: 11\n",
      "CPU times: user 13min 45s, sys: 22.5 s, total: 14min 8s\n",
      "Wall time: 17min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "if model_name not in results: results[model_name] = {}\n",
    "for t in [\n",
    "#    'mort_icu',\n",
    "    'los_3', \n",
    "#    'mort_hosp', \n",
    "#    'los_7'\n",
    "]:\n",
    "    if t not in results[model_name]: results[model_name][t] = {}\n",
    "    for n, X_train, X_dev, X_test in (\n",
    "        ('lvl2', lvl2_train, lvl2_dev, lvl2_test),\n",
    "#         ('raw', raw_train, raw_dev, raw_test)\n",
    "    ):\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        X_mean = np.nanmean(\n",
    "            to_3D_tensor(\n",
    "                X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "                np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "            ),\n",
    "            axis=0, keepdims=True\n",
    "        ).transpose([0, 2, 1])\n",
    "        base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "    \n",
    "        if n in results[model_name][t]:\n",
    "            if not RERUN: \n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                print(results[model_name][t][n])\n",
    "                continue\n",
    "            best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "            print(\"Loading best hyperparams\", best_hyperparams)\n",
    "        else:\n",
    "            best_s, best_hyperparams = -np.Inf, None\n",
    "            for i, hyperparams in enumerate(hyperparams_list):\n",
    "                print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "                early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "                batch_size = int(batch_size)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                all_train_subjects = list(\n",
    "                    np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "                )\n",
    "                N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "                train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "                early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "                X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "                Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "                X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "                Ys_train_early_stop = Ys_train[\n",
    "                    Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "                ]\n",
    "\n",
    "                train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "                early_stop_dataloader = prepare_dataloader(\n",
    "                    X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size\n",
    "                )\n",
    "                dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=batch_size)\n",
    "                test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "                model_hyperparams = copy.copy(base_params)\n",
    "                model_hyperparams.update(\n",
    "                    {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "                )\n",
    "                \n",
    "                batch_size = int(batch_size)\n",
    "                model = GRUD(**model_hyperparams)\n",
    "\n",
    "                best_model, _ = Train_Model(\n",
    "                    model, train_dataloader, early_stop_dataloader,\n",
    "                    **{k: v for k, v in hyperparams.items() if k in (\n",
    "                        'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                    )}\n",
    "                )\n",
    "\n",
    "                probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "                probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "                labels_dev        = np.concatenate(labels_dev)\n",
    "                s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "                if s > best_s:\n",
    "                    best_s, best_hyperparams = s, hyperparams\n",
    "                    print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "        ## Test\n",
    "        try:\n",
    "            np.random.seed(seed)\n",
    "            hyperparams = best_hyperparams # In case I forgot a replace below\n",
    "            early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "            batch_size = int(batch_size)\n",
    "            X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "\n",
    "            all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "            N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "            train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "            X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "            Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "            X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "            Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "            train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "            early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "            test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "            model_hyperparams = copy.copy(base_params)\n",
    "            model_hyperparams.update(\n",
    "                {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "            )\n",
    "            model = GRUD(**model_hyperparams)\n",
    "\n",
    "            best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "                model, train_dataloader, early_stop_dataloader,\n",
    "                **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "                    'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                )}\n",
    "            )\n",
    "\n",
    "            probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "            y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "            y_pred  = np.argmax(probabilities_test)\n",
    "            y_true  = np.concatenate(labels_test)\n",
    "\n",
    "            auc   = roc_auc_score(y_true, y_score)\n",
    "            auprc = average_precision_score(y_true, y_score)\n",
    "            acc   = accuracy_score(y_true, y_pred)\n",
    "            F1    = f1_score(y_true, y_pred)\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(auc, auprc, acc, F1)\n",
    "\n",
    "            results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "            #with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results for model GRU-D on target los_3 with representation lvl2\n",
      "0.6829013396361199 0.6356465917949119 0.6411201179071481 0.5965202982601492\n"
     ]
    }
   ],
   "source": [
    "y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "y_true  = np.concatenate(labels_test)\n",
    "\n",
    "y_score  = np.nan_to_num(y_score , nan=0, posinf=0)\n",
    "y_pred  = np.nan_to_num(y_pred , nan=0, posinf=0)\n",
    "y_true  = np.nan_to_num(y_true , nan=0, posinf=0)\n",
    "\n",
    "auc   = roc_auc_score(y_true, y_score)\n",
    "auprc = average_precision_score(y_true, y_score)\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "F1    = f1_score(y_true, y_pred)\n",
    "print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "print(auc, auprc, acc, F1)\n",
    "\n",
    "#results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target mort_hosp with representation lvl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
      "<timed exec>:17: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81440755, valid_loss: 0.77412806, time: [4.88], best model: 1\n",
      "Epoch: 1, train_loss: 0.69040926, valid_loss: 0.6817498, time: [4.89], best model: 1\n",
      "Epoch: 2, train_loss: 0.62892954, valid_loss: 0.61730224, time: [4.88], best model: 1\n",
      "Epoch: 3, train_loss: 0.57724521, valid_loss: 0.55780406, time: [4.89], best model: 1\n",
      "Epoch: 4, train_loss: 0.51745109, valid_loss: 0.52791756, time: [4.89], best model: 1\n",
      "Epoch: 5, train_loss: 0.48307283, valid_loss: 0.50812069, time: [5.02], best model: 1\n",
      "Epoch: 6, train_loss: 0.45985894, valid_loss: 0.4879048, time: [5.], best model: 1\n",
      "Epoch: 7, train_loss: 0.44175575, valid_loss: 0.4879701, time: [4.93], best model: 0\n",
      "Epoch: 8, train_loss: 0.42159738, valid_loss: 0.45659482, time: [4.84], best model: 1\n",
      "Epoch: 9, train_loss: 0.40657816, valid_loss: 0.4324658, time: [4.83], best model: 1\n",
      "Epoch: 10, train_loss: 0.39978645, valid_loss: 0.43279874, time: [4.84], best model: 0\n",
      "Epoch: 11, train_loss: 0.38226529, valid_loss: 0.43417178, time: [4.83], best model: 0\n",
      "Epoch: 12, train_loss: 0.37101964, valid_loss: 0.42812799, time: [4.84], best model: 1\n",
      "Epoch: 13, train_loss: 0.37263019, valid_loss: 0.40308345, time: [4.83], best model: 1\n",
      "Epoch: 14, train_loss: 0.3610368, valid_loss: 0.40975671, time: [4.93], best model: 0\n",
      "Epoch: 15, train_loss: 0.34186155, valid_loss: 0.40007591, time: [4.83], best model: 1\n",
      "Epoch: 16, train_loss: 0.33416128, valid_loss: 0.40061173, time: [4.85], best model: 0\n",
      "Epoch: 17, train_loss: 0.33528433, valid_loss: 0.39883855, time: [4.85], best model: 1\n",
      "Epoch: 18, train_loss: 0.32565564, valid_loss: 0.40262212, time: [4.84], best model: 0\n",
      "Epoch: 19, train_loss: 0.31138337, valid_loss: 0.40464007, time: [4.84], best model: 0\n",
      "Epoch: 20, train_loss: 0.30401451, valid_loss: 0.39008166, time: [4.9], best model: 1\n",
      "Epoch: 21, train_loss: 0.30869522, valid_loss: 0.39736494, time: [4.84], best model: 0\n",
      "New Best Score: 80.75 @ hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496}\n",
      "On sample 2 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (rl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (hl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=77, bias=True)\n",
      "  (fc): Linear(in_features=77, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.79502716, valid_loss: 0.80783754, time: [5.9], best model: 1\n",
      "Epoch: 1, train_loss: 0.65518362, valid_loss: 0.70107491, time: [5.9], best model: 1\n",
      "Epoch: 2, train_loss: 0.58783791, valid_loss: 0.60492082, time: [5.9], best model: 1\n",
      "Epoch: 3, train_loss: 0.52766373, valid_loss: 0.54618582, time: [5.88], best model: 1\n",
      "Epoch: 4, train_loss: 0.46994057, valid_loss: 0.49760791, time: [5.9], best model: 1\n",
      "Epoch: 5, train_loss: 0.44512079, valid_loss: 0.45518872, time: [5.94], best model: 1\n",
      "Epoch: 6, train_loss: 0.42621918, valid_loss: 0.45269345, time: [5.91], best model: 1\n",
      "Epoch: 7, train_loss: 0.39695861, valid_loss: 0.44379387, time: [5.92], best model: 1\n",
      "Epoch: 8, train_loss: 0.39042188, valid_loss: 0.41035437, time: [5.98], best model: 1\n",
      "Epoch: 9, train_loss: 0.36758967, valid_loss: 0.41054833, time: [5.92], best model: 0\n",
      "Epoch: 10, train_loss: 0.36585676, valid_loss: 0.40012536, time: [5.9], best model: 1\n",
      "Epoch: 11, train_loss: 0.35254829, valid_loss: 0.40551016, time: [5.85], best model: 0\n",
      "Epoch: 12, train_loss: 0.34219693, valid_loss: 0.39679531, time: [5.85], best model: 1\n",
      "Epoch: 13, train_loss: 0.33733181, valid_loss: 0.38771622, time: [5.85], best model: 1\n",
      "Epoch: 14, train_loss: 0.3279085, valid_loss: 0.38643421, time: [5.85], best model: 1\n",
      "Epoch: 15, train_loss: 0.32368826, valid_loss: 0.38726952, time: [5.9], best model: 0\n",
      "Epoch: 16, train_loss: 0.31991126, valid_loss: 0.39238912, time: [5.93], best model: 0\n",
      "Epoch: 17, train_loss: 0.31079736, valid_loss: 0.39496394, time: [5.92], best model: 0\n",
      "Epoch: 18, train_loss: 0.29709115, valid_loss: 0.41082909, time: [5.92], best model: 0\n",
      "Early Stopped at Epoch: 19\n",
      "New Best Score: 81.47 @ hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429}\n",
      "On sample 3 / 10 (hyperparams = {'cell_size': 62, 'hidden_size': 72, 'learning_rate': 0.08981174363909455, 'num_epochs': 76, 'patience': 4, 'batch_size': 39, 'early_stop_frac': 0.14888610889064946, 'seed': 156})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (rl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (hl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=72, bias=True)\n",
      "  (fc): Linear(in_features=72, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78658367, valid_loss: 0.79047481, time: [5.5], best model: 1\n",
      "Epoch: 1, train_loss: 0.68595399, valid_loss: 0.67531157, time: [5.44], best model: 1\n",
      "Epoch: 2, train_loss: 0.59827772, valid_loss: 0.59407305, time: [5.45], best model: 1\n",
      "Epoch: 3, train_loss: 0.54135524, valid_loss: 0.54531766, time: [5.44], best model: 1\n",
      "Epoch: 4, train_loss: 0.48457605, valid_loss: 0.50026601, time: [5.45], best model: 1\n",
      "Epoch: 5, train_loss: 0.45490792, valid_loss: 0.46336165, time: [5.48], best model: 1\n",
      "Epoch: 6, train_loss: 0.420839, valid_loss: 0.46071665, time: [5.47], best model: 1\n",
      "Epoch: 7, train_loss: 0.40421866, valid_loss: 0.43001288, time: [5.48], best model: 1\n",
      "Epoch: 8, train_loss: 0.38620358, valid_loss: 0.42487372, time: [5.49], best model: 1\n",
      "Epoch: 9, train_loss: 0.37587978, valid_loss: 0.41798285, time: [5.49], best model: 1\n",
      "Epoch: 10, train_loss: 0.36588571, valid_loss: 0.40905391, time: [5.5], best model: 1\n",
      "Epoch: 11, train_loss: 0.35930466, valid_loss: 0.41909405, time: [5.5], best model: 0\n",
      "Epoch: 12, train_loss: 0.34728259, valid_loss: 0.4057005, time: [5.6], best model: 1\n",
      "Epoch: 13, train_loss: 0.33254798, valid_loss: 0.41003992, time: [5.73], best model: 0\n",
      "Epoch: 14, train_loss: 0.32323935, valid_loss: 0.40217289, time: [5.65], best model: 1\n",
      "Epoch: 15, train_loss: 0.32415405, valid_loss: 0.40411457, time: [5.61], best model: 0\n",
      "Epoch: 16, train_loss: 0.31889928, valid_loss: 0.40290117, time: [5.62], best model: 0\n",
      "Epoch: 17, train_loss: 0.31646616, valid_loss: 0.37978981, time: [5.52], best model: 1\n",
      "Epoch: 18, train_loss: 0.30456007, valid_loss: 0.40373346, time: [5.51], best model: 0\n",
      "Epoch: 19, train_loss: 0.29203835, valid_loss: 0.40973809, time: [5.51], best model: 0\n",
      "Epoch: 20, train_loss: 0.28601408, valid_loss: 0.41132358, time: [5.51], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 4 / 10 (hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (rl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (hl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=78, bias=True)\n",
      "  (fc): Linear(in_features=78, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81663685, valid_loss: 0.77445893, time: [5.02], best model: 1\n",
      "Epoch: 1, train_loss: 0.72433853, valid_loss: 0.70656457, time: [5.], best model: 1\n",
      "Epoch: 2, train_loss: 0.63996694, valid_loss: 0.61652605, time: [5.], best model: 1\n",
      "Epoch: 3, train_loss: 0.58222827, valid_loss: 0.56801132, time: [5.], best model: 1\n",
      "Epoch: 4, train_loss: 0.5234692, valid_loss: 0.53715467, time: [5.02], best model: 1\n",
      "Epoch: 5, train_loss: 0.50383119, valid_loss: 0.51074385, time: [5.], best model: 1\n",
      "Epoch: 6, train_loss: 0.46076761, valid_loss: 0.47537651, time: [5.01], best model: 1\n",
      "Epoch: 7, train_loss: 0.44149396, valid_loss: 0.4680684, time: [5.01], best model: 1\n",
      "Epoch: 8, train_loss: 0.4168418, valid_loss: 0.45602138, time: [5.02], best model: 1\n",
      "Epoch: 9, train_loss: 0.40829916, valid_loss: 0.44246255, time: [5.01], best model: 1\n",
      "Epoch: 10, train_loss: 0.38707701, valid_loss: 0.44529966, time: [5.06], best model: 0\n",
      "Epoch: 11, train_loss: 0.38445038, valid_loss: 0.44286349, time: [5.01], best model: 0\n",
      "Epoch: 12, train_loss: 0.37653775, valid_loss: 0.42825317, time: [5.02], best model: 1\n",
      "Epoch: 13, train_loss: 0.35575101, valid_loss: 0.42668477, time: [5.01], best model: 1\n",
      "Epoch: 14, train_loss: 0.35484669, valid_loss: 0.42397491, time: [5.], best model: 1\n",
      "Epoch: 15, train_loss: 0.3397512, valid_loss: 0.41521255, time: [4.99], best model: 1\n",
      "Epoch: 16, train_loss: 0.33284751, valid_loss: 0.43583566, time: [5.02], best model: 0\n",
      "Epoch: 17, train_loss: 0.32164592, valid_loss: 0.43070729, time: [5.02], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "New Best Score: 81.66 @ hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410}\n",
      "On sample 5 / 10 (hyperparams = {'cell_size': 59, 'hidden_size': 93, 'learning_rate': 0.06904675101784023, 'num_epochs': 72, 'patience': 5, 'batch_size': 52, 'early_stop_frac': 0.07804439920644052, 'seed': 649})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (rl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (hl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=93, bias=True)\n",
      "  (fc): Linear(in_features=93, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78924587, valid_loss: 0.89670168, time: [6.1], best model: 1\n",
      "Epoch: 1, train_loss: 0.67305464, valid_loss: 0.76194718, time: [6.1], best model: 1\n",
      "Epoch: 2, train_loss: 0.58238965, valid_loss: 0.72928121, time: [6.09], best model: 1\n",
      "Epoch: 3, train_loss: 0.54019138, valid_loss: 0.6570851, time: [6.08], best model: 1\n",
      "Epoch: 4, train_loss: 0.50194294, valid_loss: 0.59622053, time: [6.08], best model: 1\n",
      "Epoch: 5, train_loss: 0.45504756, valid_loss: 0.5817237, time: [6.1], best model: 1\n",
      "Epoch: 6, train_loss: 0.43988324, valid_loss: 0.54637334, time: [6.1], best model: 1\n",
      "Epoch: 7, train_loss: 0.41346436, valid_loss: 0.52241072, time: [6.11], best model: 1\n",
      "Epoch: 8, train_loss: 0.40247821, valid_loss: 0.51827011, time: [6.1], best model: 1\n",
      "Epoch: 9, train_loss: 0.40270902, valid_loss: 0.49303185, time: [6.1], best model: 1\n",
      "Epoch: 10, train_loss: 0.37847465, valid_loss: 0.45869841, time: [6.1], best model: 1\n",
      "Epoch: 11, train_loss: 0.35615463, valid_loss: 0.46981044, time: [6.12], best model: 0\n",
      "Epoch: 12, train_loss: 0.35651914, valid_loss: 0.44848817, time: [6.12], best model: 1\n",
      "Epoch: 13, train_loss: 0.36062602, valid_loss: 0.43944352, time: [6.11], best model: 1\n",
      "Epoch: 14, train_loss: 0.3360519, valid_loss: 0.45390912, time: [6.24], best model: 0\n",
      "Epoch: 15, train_loss: 0.33807683, valid_loss: 0.44049956, time: [6.22], best model: 0\n",
      "Epoch: 16, train_loss: 0.32061617, valid_loss: 0.45909747, time: [6.12], best model: 0\n",
      "Epoch: 17, train_loss: 0.31749923, valid_loss: 0.43147493, time: [6.13], best model: 1\n",
      "Epoch: 18, train_loss: 0.31105434, valid_loss: 0.45693036, time: [6.15], best model: 0\n",
      "Epoch: 19, train_loss: 0.30338763, valid_loss: 0.44119801, time: [6.18], best model: 0\n",
      "Epoch: 20, train_loss: 0.29239228, valid_loss: 0.44841304, time: [6.16], best model: 0\n",
      "Epoch: 21, train_loss: 0.29056105, valid_loss: 0.46109462, time: [6.15], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "New Best Score: 82.00 @ hyperparams = {'cell_size': 59, 'hidden_size': 93, 'learning_rate': 0.06904675101784023, 'num_epochs': 72, 'patience': 5, 'batch_size': 52, 'early_stop_frac': 0.07804439920644052, 'seed': 649}\n",
      "On sample 6 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 71, 'learning_rate': 0.0437304802367127, 'num_epochs': 16, 'patience': 6, 'batch_size': 46, 'early_stop_frac': 0.12892793284514886, 'seed': 9505})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (rl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (hl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=71, bias=True)\n",
      "  (fc): Linear(in_features=71, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81013103, valid_loss: 0.83676525, time: [5.29], best model: 1\n",
      "Epoch: 1, train_loss: 0.6730817, valid_loss: 0.72735235, time: [5.26], best model: 1\n",
      "Epoch: 2, train_loss: 0.60596038, valid_loss: 0.67318394, time: [5.26], best model: 1\n",
      "Epoch: 3, train_loss: 0.53360237, valid_loss: 0.62463031, time: [5.26], best model: 1\n",
      "Epoch: 4, train_loss: 0.50589585, valid_loss: 0.57190428, time: [5.25], best model: 1\n",
      "Epoch: 5, train_loss: 0.45282054, valid_loss: 0.51967147, time: [5.26], best model: 1\n",
      "Epoch: 6, train_loss: 0.42625997, valid_loss: 0.49644458, time: [5.26], best model: 1\n",
      "Epoch: 7, train_loss: 0.41262683, valid_loss: 0.46762404, time: [5.26], best model: 1\n",
      "Epoch: 8, train_loss: 0.40699261, valid_loss: 0.48011998, time: [5.28], best model: 0\n",
      "Epoch: 9, train_loss: 0.39068641, valid_loss: 0.45576305, time: [5.27], best model: 1\n",
      "Epoch: 10, train_loss: 0.36427056, valid_loss: 0.43563357, time: [5.27], best model: 1\n",
      "Epoch: 11, train_loss: 0.36514031, valid_loss: 0.42725498, time: [5.28], best model: 1\n",
      "Epoch: 12, train_loss: 0.36377037, valid_loss: 0.41895164, time: [5.28], best model: 1\n",
      "Epoch: 13, train_loss: 0.35468812, valid_loss: 0.41720271, time: [5.28], best model: 1\n",
      "Epoch: 14, train_loss: 0.34313707, valid_loss: 0.432373, time: [5.39], best model: 0\n",
      "Epoch: 15, train_loss: 0.32845619, valid_loss: 0.42103602, time: [5.55], best model: 0\n",
      "On sample 7 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 90, 'learning_rate': 0.05786898284457517, 'num_epochs': 143, 'patience': 6, 'batch_size': 47, 'early_stop_frac': 0.06032260065776421, 'seed': 7587})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (rl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (hl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=90, bias=True)\n",
      "  (fc): Linear(in_features=90, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.79145757, valid_loss: 0.76784237, time: [6.46], best model: 1\n",
      "Epoch: 1, train_loss: 0.66912524, valid_loss: 0.63346366, time: [6.3], best model: 1\n",
      "Epoch: 2, train_loss: 0.59062926, valid_loss: 0.58112605, time: [6.42], best model: 1\n",
      "Epoch: 3, train_loss: 0.52561001, valid_loss: 0.50935813, time: [6.35], best model: 1\n",
      "Epoch: 4, train_loss: 0.48938004, valid_loss: 0.48834018, time: [6.39], best model: 1\n",
      "Epoch: 5, train_loss: 0.46056875, valid_loss: 0.47141973, time: [6.56], best model: 1\n",
      "Epoch: 6, train_loss: 0.43019847, valid_loss: 0.46665259, time: [6.52], best model: 1\n",
      "Epoch: 7, train_loss: 0.41583824, valid_loss: 0.44903926, time: [6.35], best model: 1\n",
      "Epoch: 8, train_loss: 0.40657794, valid_loss: 0.43636648, time: [6.36], best model: 1\n",
      "Epoch: 9, train_loss: 0.38377496, valid_loss: 0.42620599, time: [6.35], best model: 1\n",
      "Epoch: 10, train_loss: 0.36944405, valid_loss: 0.40764276, time: [6.37], best model: 1\n",
      "Epoch: 11, train_loss: 0.3600144, valid_loss: 0.41612093, time: [6.35], best model: 0\n",
      "Epoch: 12, train_loss: 0.34934056, valid_loss: 0.40429465, time: [6.36], best model: 1\n",
      "Epoch: 13, train_loss: 0.3394926, valid_loss: 0.4072909, time: [6.37], best model: 0\n",
      "Epoch: 14, train_loss: 0.33186889, valid_loss: 0.39043999, time: [6.36], best model: 1\n",
      "Epoch: 15, train_loss: 0.32478368, valid_loss: 0.40642647, time: [6.38], best model: 0\n",
      "Epoch: 16, train_loss: 0.32740992, valid_loss: 0.39570777, time: [6.35], best model: 0\n",
      "Epoch: 17, train_loss: 0.31573395, valid_loss: 0.39334619, time: [6.37], best model: 0\n",
      "Epoch: 18, train_loss: 0.30997596, valid_loss: 0.39222936, time: [6.38], best model: 0\n",
      "Epoch: 19, train_loss: 0.3027639, valid_loss: 0.41756523, time: [6.36], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "New Best Score: 82.92 @ hyperparams = {'cell_size': 55, 'hidden_size': 90, 'learning_rate': 0.05786898284457517, 'num_epochs': 143, 'patience': 6, 'batch_size': 47, 'early_stop_frac': 0.06032260065776421, 'seed': 7587}\n",
      "On sample 8 / 10 (hyperparams = {'cell_size': 65, 'hidden_size': 83, 'learning_rate': 0.016038693859523376, 'num_epochs': 75, 'patience': 5, 'batch_size': 61, 'early_stop_frac': 0.09478935261759053, 'seed': 1680})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (rl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (hl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=83, bias=True)\n",
      "  (fc): Linear(in_features=83, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.8223856, valid_loss: 0.84890607, time: [5.36], best model: 1\n",
      "Epoch: 1, train_loss: 0.66473324, valid_loss: 0.7272543, time: [5.36], best model: 1\n",
      "Epoch: 2, train_loss: 0.61902522, valid_loss: 0.67365485, time: [5.36], best model: 1\n",
      "Epoch: 3, train_loss: 0.55956419, valid_loss: 0.62025522, time: [5.34], best model: 1\n",
      "Epoch: 4, train_loss: 0.53188136, valid_loss: 0.5602842, time: [5.35], best model: 1\n",
      "Epoch: 5, train_loss: 0.47738126, valid_loss: 0.53474937, time: [5.34], best model: 1\n",
      "Epoch: 6, train_loss: 0.46237322, valid_loss: 0.4975803, time: [5.41], best model: 1\n",
      "Epoch: 7, train_loss: 0.43839871, valid_loss: 0.49280387, time: [5.56], best model: 1\n",
      "Epoch: 8, train_loss: 0.42232438, valid_loss: 0.49457711, time: [5.5], best model: 0\n",
      "Epoch: 9, train_loss: 0.41056195, valid_loss: 0.4682031, time: [5.48], best model: 1\n",
      "Epoch: 10, train_loss: 0.38955229, valid_loss: 0.45747204, time: [5.44], best model: 1\n",
      "Epoch: 11, train_loss: 0.37675089, valid_loss: 0.44306035, time: [5.58], best model: 1\n",
      "Epoch: 12, train_loss: 0.35958631, valid_loss: 0.43525795, time: [5.37], best model: 1\n",
      "Epoch: 13, train_loss: 0.35089213, valid_loss: 0.43688325, time: [5.38], best model: 0\n",
      "Epoch: 14, train_loss: 0.35204106, valid_loss: 0.43880105, time: [5.55], best model: 0\n",
      "Epoch: 15, train_loss: 0.34116192, valid_loss: 0.43238793, time: [5.64], best model: 1\n",
      "Epoch: 16, train_loss: 0.33155433, valid_loss: 0.41558113, time: [5.61], best model: 1\n",
      "Epoch: 17, train_loss: 0.32625746, valid_loss: 0.45095583, time: [5.87], best model: 0\n",
      "Epoch: 18, train_loss: 0.32242453, valid_loss: 0.43982962, time: [5.43], best model: 0\n",
      "Epoch: 19, train_loss: 0.31349867, valid_loss: 0.43775338, time: [5.35], best model: 0\n",
      "Epoch: 20, train_loss: 0.3063715, valid_loss: 0.43801069, time: [5.32], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "On sample 9 / 10 (hyperparams = {'cell_size': 50, 'hidden_size': 85, 'learning_rate': 0.021810148908487884, 'num_epochs': 23, 'patience': 4, 'batch_size': 55, 'early_stop_frac': 0.14085955030930958, 'seed': 7256})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (rl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (hl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=85, bias=True)\n",
      "  (fc): Linear(in_features=85, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.81873586, valid_loss: 0.80879171, time: [5.47], best model: 1\n",
      "Epoch: 1, train_loss: 0.70052439, valid_loss: 0.69570913, time: [5.66], best model: 1\n",
      "Epoch: 2, train_loss: 0.61955505, valid_loss: 0.64534943, time: [5.47], best model: 1\n",
      "Epoch: 3, train_loss: 0.55446437, valid_loss: 0.61723551, time: [5.5], best model: 1\n",
      "Epoch: 4, train_loss: 0.50489207, valid_loss: 0.57743037, time: [5.63], best model: 1\n",
      "Epoch: 5, train_loss: 0.47605347, valid_loss: 0.56439809, time: [5.33], best model: 1\n",
      "Epoch: 6, train_loss: 0.45418864, valid_loss: 0.54212962, time: [5.56], best model: 1\n",
      "Epoch: 7, train_loss: 0.43857895, valid_loss: 0.51769775, time: [5.38], best model: 1\n",
      "Epoch: 8, train_loss: 0.41989044, valid_loss: 0.51406423, time: [5.29], best model: 1\n",
      "Epoch: 9, train_loss: 0.4009964, valid_loss: 0.51943934, time: [5.31], best model: 0\n",
      "Epoch: 10, train_loss: 0.39475375, valid_loss: 0.49926025, time: [5.28], best model: 1\n",
      "Epoch: 11, train_loss: 0.38278798, valid_loss: 0.50657761, time: [5.27], best model: 0\n",
      "Epoch: 12, train_loss: 0.3635291, valid_loss: 0.49004822, time: [5.28], best model: 1\n",
      "Epoch: 13, train_loss: 0.36070333, valid_loss: 0.47649343, time: [5.28], best model: 1\n",
      "Epoch: 14, train_loss: 0.35332311, valid_loss: 0.49217, time: [5.29], best model: 0\n",
      "Epoch: 15, train_loss: 0.34712069, valid_loss: 0.47539403, time: [5.3], best model: 1\n",
      "Epoch: 16, train_loss: 0.33551109, valid_loss: 0.47893936, time: [5.68], best model: 0\n",
      "Epoch: 17, train_loss: 0.33247805, valid_loss: 0.48232951, time: [5.41], best model: 0\n",
      "Epoch: 18, train_loss: 0.33381096, valid_loss: 0.48793833, time: [5.28], best model: 0\n",
      "Epoch: 19, train_loss: 0.32348674, valid_loss: 0.47084651, time: [5.42], best model: 1\n",
      "Epoch: 20, train_loss: 0.31722944, valid_loss: 0.47744064, time: [5.5], best model: 0\n",
      "Epoch: 21, train_loss: 0.30820653, valid_loss: 0.4988091, time: [5.46], best model: 0\n",
      "Epoch: 22, train_loss: 0.30280436, valid_loss: 0.47725479, time: [5.36], best model: 0\n",
      "On sample 10 / 10 (hyperparams = {'cell_size': 66, 'hidden_size': 70, 'learning_rate': 0.08207445686755367, 'num_epochs': 130, 'patience': 4, 'batch_size': 51, 'early_stop_frac': 0.07936141483736796, 'seed': 7962})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (rl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (hl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=70, bias=True)\n",
      "  (fc): Linear(in_features=70, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.78547597, valid_loss: 0.80813608, time: [5.19], best model: 1\n",
      "Epoch: 1, train_loss: 0.69134938, valid_loss: 0.70730449, time: [5.28], best model: 1\n",
      "Epoch: 2, train_loss: 0.60039613, valid_loss: 0.62607623, time: [5.18], best model: 1\n",
      "Epoch: 3, train_loss: 0.55264539, valid_loss: 0.58576841, time: [5.19], best model: 1\n",
      "Epoch: 4, train_loss: 0.51368119, valid_loss: 0.58771351, time: [5.18], best model: 0\n",
      "Epoch: 5, train_loss: 0.47254851, valid_loss: 0.53724839, time: [5.17], best model: 1\n",
      "Epoch: 6, train_loss: 0.43726247, valid_loss: 0.51570537, time: [5.18], best model: 1\n",
      "Epoch: 7, train_loss: 0.40740976, valid_loss: 0.51279756, time: [5.18], best model: 1\n",
      "Epoch: 8, train_loss: 0.39642072, valid_loss: 0.4907365, time: [5.2], best model: 1\n",
      "Epoch: 9, train_loss: 0.38571265, valid_loss: 0.47992316, time: [5.2], best model: 1\n",
      "Epoch: 10, train_loss: 0.36090913, valid_loss: 0.47780472, time: [5.17], best model: 1\n",
      "Epoch: 11, train_loss: 0.36666118, valid_loss: 0.47460033, time: [5.19], best model: 1\n",
      "Epoch: 12, train_loss: 0.35855071, valid_loss: 0.47090819, time: [5.19], best model: 1\n",
      "Epoch: 13, train_loss: 0.33340141, valid_loss: 0.46652226, time: [5.22], best model: 1\n",
      "Epoch: 14, train_loss: 0.33725592, valid_loss: 0.4838499, time: [5.2], best model: 0\n",
      "Epoch: 15, train_loss: 0.32588207, valid_loss: 0.47651344, time: [5.21], best model: 0\n",
      "Epoch: 16, train_loss: 0.32440973, valid_loss: 0.45604976, time: [5.19], best model: 1\n",
      "Epoch: 17, train_loss: 0.31242486, valid_loss: 0.48078612, time: [5.19], best model: 0\n",
      "Epoch: 18, train_loss: 0.31204284, valid_loss: 0.44970158, time: [5.18], best model: 1\n",
      "Epoch: 19, train_loss: 0.30487258, valid_loss: 0.46503932, time: [5.19], best model: 0\n",
      "Epoch: 20, train_loss: 0.29413259, valid_loss: 0.47376815, time: [5.23], best model: 0\n",
      "Epoch: 21, train_loss: 0.29036533, valid_loss: 0.48191771, time: [5.18], best model: 0\n",
      "Early Stopped at Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (rl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (hl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=90, bias=True)\n",
      "  (fc): Linear(in_features=90, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.77701597, valid_loss: 0.78637107, time: [7.24], best model: 1\n",
      "Epoch: 1, train_loss: 0.67120361, valid_loss: 0.68088594, time: [7.21], best model: 1\n",
      "Epoch: 2, train_loss: 0.58633129, valid_loss: 0.60316985, time: [7.22], best model: 1\n",
      "Epoch: 3, train_loss: 0.51151346, valid_loss: 0.56029143, time: [7.22], best model: 1\n",
      "Epoch: 4, train_loss: 0.4720684, valid_loss: 0.51903943, time: [7.2], best model: 1\n",
      "Epoch: 5, train_loss: 0.44606172, valid_loss: 0.49256194, time: [7.24], best model: 1\n",
      "Epoch: 6, train_loss: 0.41861504, valid_loss: 0.46941194, time: [7.23], best model: 1\n",
      "Epoch: 7, train_loss: 0.40369387, valid_loss: 0.45167307, time: [7.22], best model: 1\n",
      "Epoch: 8, train_loss: 0.38588183, valid_loss: 0.44661685, time: [7.21], best model: 1\n",
      "Epoch: 9, train_loss: 0.37742398, valid_loss: 0.43802188, time: [7.23], best model: 1\n",
      "Epoch: 10, train_loss: 0.35688099, valid_loss: 0.43472423, time: [7.22], best model: 1\n",
      "Epoch: 11, train_loss: 0.35564836, valid_loss: 0.42818815, time: [7.24], best model: 1\n",
      "Epoch: 12, train_loss: 0.34447287, valid_loss: 0.43220016, time: [7.4], best model: 0\n",
      "Epoch: 13, train_loss: 0.3317344, valid_loss: 0.43417897, time: [7.46], best model: 0\n",
      "Epoch: 14, train_loss: 0.33143833, valid_loss: 0.44005385, time: [7.34], best model: 0\n",
      "Epoch: 15, train_loss: 0.32819639, valid_loss: 0.42540625, time: [7.44], best model: 1\n",
      "Epoch: 16, train_loss: 0.32414911, valid_loss: 0.43701553, time: [7.35], best model: 0\n",
      "Epoch: 17, train_loss: 0.31117655, valid_loss: 0.43504662, time: [7.42], best model: 0\n",
      "Epoch: 18, train_loss: 0.30341469, valid_loss: 0.44187, time: [7.21], best model: 0\n",
      "Epoch: 19, train_loss: 0.30335554, valid_loss: 0.44807676, time: [7.24], best model: 0\n",
      "Epoch: 20, train_loss: 0.28172014, valid_loss: 0.45019062, time: [7.23], best model: 0\n",
      "Early Stopped at Epoch: 21\n",
      "CPU times: user 21min 55s, sys: 34.1 s, total: 22min 29s\n",
      "Wall time: 22min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "if model_name not in results: results[model_name] = {}\n",
    "for t in [\n",
    "#    'mort_icu',\n",
    "#    'los_3', \n",
    "    'mort_hosp', \n",
    "#    'los_7'\n",
    "]:\n",
    "    if t not in results[model_name]: results[model_name][t] = {}\n",
    "    for n, X_train, X_dev, X_test in (\n",
    "        ('lvl2', lvl2_train, lvl2_dev, lvl2_test),\n",
    "#         ('raw', raw_train, raw_dev, raw_test)\n",
    "    ):\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        X_mean = np.nanmean(\n",
    "            to_3D_tensor(\n",
    "                X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "                np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "            ),\n",
    "            axis=0, keepdims=True\n",
    "        ).transpose([0, 2, 1])\n",
    "        base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "    \n",
    "        if n in results[model_name][t]:\n",
    "            if not RERUN: \n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                print(results[model_name][t][n])\n",
    "                continue\n",
    "            best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "            print(\"Loading best hyperparams\", best_hyperparams)\n",
    "        else:\n",
    "            best_s, best_hyperparams = -np.Inf, None\n",
    "            for i, hyperparams in enumerate(hyperparams_list):\n",
    "                print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "                early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "                batch_size = int(batch_size)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                all_train_subjects = list(\n",
    "                    np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "                )\n",
    "                N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "                train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "                early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "                X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "                Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "                X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "                Ys_train_early_stop = Ys_train[\n",
    "                    Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "                ]\n",
    "\n",
    "                train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "                early_stop_dataloader = prepare_dataloader(\n",
    "                    X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size\n",
    "                )\n",
    "                dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=batch_size)\n",
    "                test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "                model_hyperparams = copy.copy(base_params)\n",
    "                model_hyperparams.update(\n",
    "                    {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "                )\n",
    "                \n",
    "                batch_size = int(batch_size)\n",
    "                model = GRUD(**model_hyperparams)\n",
    "\n",
    "                best_model, _ = Train_Model(\n",
    "                    model, train_dataloader, early_stop_dataloader,\n",
    "                    **{k: v for k, v in hyperparams.items() if k in (\n",
    "                        'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                    )}\n",
    "                )\n",
    "\n",
    "                probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "                probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "                labels_dev        = np.concatenate(labels_dev)\n",
    "                s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "                if s > best_s:\n",
    "                    best_s, best_hyperparams = s, hyperparams\n",
    "                    print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "        ## Test\n",
    "        try:\n",
    "            np.random.seed(seed)\n",
    "            hyperparams = best_hyperparams # In case I forgot a replace below\n",
    "            early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "            batch_size = int(batch_size)\n",
    "            X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "\n",
    "            all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "            N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "            train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "            X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "            Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "            X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "            Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "            train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "            early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "            test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "            model_hyperparams = copy.copy(base_params)\n",
    "            model_hyperparams.update(\n",
    "                {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "            )\n",
    "            model = GRUD(**model_hyperparams)\n",
    "\n",
    "            best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "                model, train_dataloader, early_stop_dataloader,\n",
    "                **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "                    'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                )}\n",
    "            )\n",
    "\n",
    "            probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "            y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "            y_pred  = np.argmax(probabilities_test)\n",
    "            y_true  = np.concatenate(labels_test)\n",
    "\n",
    "            auc   = roc_auc_score(y_true, y_score)\n",
    "            auprc = average_precision_score(y_true, y_score)\n",
    "            acc   = accuracy_score(y_true, y_pred)\n",
    "            F1    = f1_score(y_true, y_pred)\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(auc, auprc, acc, F1)\n",
    "\n",
    "            results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "            #with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results for model GRU-D on target mort_hosp with representation lvl2\n",
      "0.8226327445578784 0.5392050965807662 0.900953778429934 0.5229681978798586\n"
     ]
    }
   ],
   "source": [
    "y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "y_true  = np.concatenate(labels_test)\n",
    "\n",
    "y_score  = np.nan_to_num(y_score , nan=0, posinf=0)\n",
    "y_pred  = np.nan_to_num(y_pred , nan=0, posinf=0)\n",
    "y_true  = np.nan_to_num(y_true , nan=0, posinf=0)\n",
    "\n",
    "auc   = roc_auc_score(y_true, y_score)\n",
    "auprc = average_precision_score(y_true, y_score)\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "F1    = f1_score(y_true, y_pred)\n",
    "print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "print(auc, auprc, acc, F1)\n",
    "\n",
    "results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "#with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target los_7 with representation lvl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
      "<timed exec>:17: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.84703335, valid_loss: 0.84791756, time: [4.92], best model: 1\n",
      "Epoch: 1, train_loss: 0.74589569, valid_loss: 0.75291448, time: [4.9], best model: 1\n",
      "Epoch: 2, train_loss: 0.69429483, valid_loss: 0.67997415, time: [4.9], best model: 1\n",
      "Epoch: 3, train_loss: 0.63072978, valid_loss: 0.62691397, time: [4.9], best model: 1\n",
      "Epoch: 4, train_loss: 0.5770344, valid_loss: 0.58017751, time: [4.9], best model: 1\n",
      "Epoch: 5, train_loss: 0.55718166, valid_loss: 0.54201166, time: [4.9], best model: 1\n",
      "Epoch: 6, train_loss: 0.50619396, valid_loss: 0.51423339, time: [4.9], best model: 1\n",
      "Epoch: 7, train_loss: 0.47811092, valid_loss: 0.48072152, time: [4.91], best model: 1\n",
      "Epoch: 8, train_loss: 0.47559276, valid_loss: 0.45646898, time: [4.91], best model: 1\n",
      "Epoch: 9, train_loss: 0.44755554, valid_loss: 0.44823637, time: [4.92], best model: 1\n",
      "Epoch: 10, train_loss: 0.42840837, valid_loss: 0.42979858, time: [4.9], best model: 1\n",
      "Epoch: 11, train_loss: 0.41102861, valid_loss: 0.42392048, time: [4.91], best model: 1\n",
      "Epoch: 12, train_loss: 0.3916121, valid_loss: 0.40619398, time: [4.91], best model: 1\n",
      "Epoch: 13, train_loss: 0.3807298, valid_loss: 0.4070924, time: [4.9], best model: 0\n",
      "Epoch: 14, train_loss: 0.36897709, valid_loss: 0.39096243, time: [4.91], best model: 1\n",
      "Epoch: 15, train_loss: 0.34951463, valid_loss: 0.38247565, time: [4.92], best model: 1\n",
      "Epoch: 16, train_loss: 0.34837791, valid_loss: 0.38678611, time: [4.91], best model: 0\n",
      "Epoch: 17, train_loss: 0.33524056, valid_loss: 0.39409296, time: [4.89], best model: 0\n",
      "Epoch: 18, train_loss: 0.3247118, valid_loss: 0.38004664, time: [4.9], best model: 1\n",
      "Epoch: 19, train_loss: 0.31678268, valid_loss: 0.40188174, time: [4.9], best model: 0\n",
      "Epoch: 20, train_loss: 0.3121294, valid_loss: 0.40401007, time: [4.91], best model: 0\n",
      "Epoch: 21, train_loss: 0.30232786, valid_loss: 0.38811945, time: [4.9], best model: 0\n",
      "New Best Score: 62.46 @ hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496}\n",
      "On sample 2 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (rl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (hl): Linear(in_features=285, out_features=77, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=77, bias=True)\n",
      "  (fc): Linear(in_features=77, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83941241, valid_loss: 0.82581995, time: [5.94], best model: 1\n",
      "Epoch: 1, train_loss: 0.71951696, valid_loss: 0.7286773, time: [5.94], best model: 1\n",
      "Epoch: 2, train_loss: 0.62234969, valid_loss: 0.63077101, time: [5.94], best model: 1\n",
      "Epoch: 3, train_loss: 0.56269923, valid_loss: 0.56069804, time: [5.96], best model: 1\n",
      "Epoch: 4, train_loss: 0.53207789, valid_loss: 0.53522124, time: [5.96], best model: 1\n",
      "Epoch: 5, train_loss: 0.4846464, valid_loss: 0.48643948, time: [5.91], best model: 1\n",
      "Epoch: 6, train_loss: 0.46775107, valid_loss: 0.46695179, time: [5.91], best model: 1\n",
      "Epoch: 7, train_loss: 0.42990449, valid_loss: 0.43576549, time: [5.92], best model: 1\n",
      "Epoch: 8, train_loss: 0.41682195, valid_loss: 0.43063601, time: [5.94], best model: 1\n",
      "Epoch: 9, train_loss: 0.40973545, valid_loss: 0.41391303, time: [5.95], best model: 1\n",
      "Epoch: 10, train_loss: 0.38480696, valid_loss: 0.39696097, time: [5.94], best model: 1\n",
      "Epoch: 11, train_loss: 0.35831753, valid_loss: 0.39405674, time: [5.93], best model: 1\n",
      "Epoch: 12, train_loss: 0.35930679, valid_loss: 0.39060357, time: [5.96], best model: 1\n",
      "Epoch: 13, train_loss: 0.35583638, valid_loss: 0.38695079, time: [5.99], best model: 1\n",
      "Epoch: 14, train_loss: 0.34400742, valid_loss: 0.39584583, time: [5.95], best model: 0\n",
      "Epoch: 15, train_loss: 0.33490888, valid_loss: 0.39126944, time: [5.95], best model: 0\n",
      "Epoch: 16, train_loss: 0.33344161, valid_loss: 0.41061765, time: [5.96], best model: 0\n",
      "Epoch: 17, train_loss: 0.3153217, valid_loss: 0.39378444, time: [5.97], best model: 0\n",
      "Early Stopped at Epoch: 18\n",
      "New Best Score: 64.92 @ hyperparams = {'cell_size': 61, 'hidden_size': 77, 'learning_rate': 0.022445224973151746, 'num_epochs': 78, 'patience': 5, 'batch_size': 38, 'early_stop_frac': 0.12501443149449676, 'seed': 3429}\n",
      "On sample 3 / 10 (hyperparams = {'cell_size': 62, 'hidden_size': 72, 'learning_rate': 0.08981174363909455, 'num_epochs': 76, 'patience': 4, 'batch_size': 39, 'early_stop_frac': 0.14888610889064946, 'seed': 156})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (rl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (hl): Linear(in_features=280, out_features=72, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=72, bias=True)\n",
      "  (fc): Linear(in_features=72, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83431491, valid_loss: 0.82756101, time: [5.49], best model: 1\n",
      "Epoch: 1, train_loss: 0.70654159, valid_loss: 0.70449546, time: [5.44], best model: 1\n",
      "Epoch: 2, train_loss: 0.62540283, valid_loss: 0.62708849, time: [5.47], best model: 1\n",
      "Epoch: 3, train_loss: 0.56546613, valid_loss: 0.58248465, time: [5.45], best model: 1\n",
      "Epoch: 4, train_loss: 0.52933411, valid_loss: 0.54160763, time: [5.46], best model: 1\n",
      "Epoch: 5, train_loss: 0.49791936, valid_loss: 0.51817463, time: [5.48], best model: 1\n",
      "Epoch: 6, train_loss: 0.47895511, valid_loss: 0.47901306, time: [5.5], best model: 1\n",
      "Epoch: 7, train_loss: 0.44183698, valid_loss: 0.45992824, time: [5.49], best model: 1\n",
      "Epoch: 8, train_loss: 0.42226661, valid_loss: 0.44106402, time: [5.49], best model: 1\n",
      "Epoch: 9, train_loss: 0.41076264, valid_loss: 0.43544112, time: [5.54], best model: 1\n",
      "Epoch: 10, train_loss: 0.39127295, valid_loss: 0.41715237, time: [5.66], best model: 1\n",
      "Epoch: 11, train_loss: 0.36911378, valid_loss: 0.40645465, time: [5.66], best model: 1\n",
      "Epoch: 12, train_loss: 0.35783713, valid_loss: 0.40982931, time: [5.55], best model: 0\n",
      "Epoch: 13, train_loss: 0.34527686, valid_loss: 0.40653236, time: [5.69], best model: 0\n",
      "Epoch: 14, train_loss: 0.34417587, valid_loss: 0.40172239, time: [5.57], best model: 1\n",
      "Epoch: 15, train_loss: 0.32645914, valid_loss: 0.40921318, time: [5.58], best model: 0\n",
      "Epoch: 16, train_loss: 0.32054847, valid_loss: 0.41985506, time: [5.55], best model: 0\n",
      "Epoch: 17, train_loss: 0.31296892, valid_loss: 0.40410592, time: [5.59], best model: 0\n",
      "Epoch: 18, train_loss: 0.31023556, valid_loss: 0.39865269, time: [5.53], best model: 1\n",
      "Epoch: 19, train_loss: 0.30170288, valid_loss: 0.41261393, time: [5.5], best model: 0\n",
      "Epoch: 20, train_loss: 0.29693371, valid_loss: 0.42398031, time: [5.5], best model: 0\n",
      "Epoch: 21, train_loss: 0.28258658, valid_loss: 0.4283585, time: [5.49], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "New Best Score: 67.21 @ hyperparams = {'cell_size': 62, 'hidden_size': 72, 'learning_rate': 0.08981174363909455, 'num_epochs': 76, 'patience': 4, 'batch_size': 39, 'early_stop_frac': 0.14888610889064946, 'seed': 156}\n",
      "On sample 4 / 10 (hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (rl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (hl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=78, bias=True)\n",
      "  (fc): Linear(in_features=78, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.86656619, valid_loss: 0.86549689, time: [5.07], best model: 1\n",
      "Epoch: 1, train_loss: 0.76099186, valid_loss: 0.7601796, time: [5.04], best model: 1\n",
      "Epoch: 2, train_loss: 0.67826859, valid_loss: 0.71596892, time: [5.04], best model: 1\n",
      "Epoch: 3, train_loss: 0.65001345, valid_loss: 0.65422751, time: [5.01], best model: 1\n",
      "Epoch: 4, train_loss: 0.60669703, valid_loss: 0.60679229, time: [5.03], best model: 1\n",
      "Epoch: 5, train_loss: 0.54334565, valid_loss: 0.5622565, time: [5.02], best model: 1\n",
      "Epoch: 6, train_loss: 0.51883617, valid_loss: 0.54497265, time: [5.03], best model: 1\n",
      "Epoch: 7, train_loss: 0.4893001, valid_loss: 0.50977239, time: [5.01], best model: 1\n",
      "Epoch: 8, train_loss: 0.47606192, valid_loss: 0.4828683, time: [5.02], best model: 1\n",
      "Epoch: 9, train_loss: 0.4458908, valid_loss: 0.48415708, time: [5.03], best model: 0\n",
      "Epoch: 10, train_loss: 0.4352378, valid_loss: 0.45899953, time: [5.01], best model: 1\n",
      "Epoch: 11, train_loss: 0.41361363, valid_loss: 0.44040599, time: [5.05], best model: 1\n",
      "Epoch: 12, train_loss: 0.39394714, valid_loss: 0.43585753, time: [5.07], best model: 1\n",
      "Epoch: 13, train_loss: 0.38091114, valid_loss: 0.42893125, time: [5.03], best model: 1\n",
      "Epoch: 14, train_loss: 0.36703287, valid_loss: 0.42915801, time: [5.03], best model: 0\n",
      "Epoch: 15, train_loss: 0.3593516, valid_loss: 0.42142903, time: [5.03], best model: 1\n",
      "Epoch: 16, train_loss: 0.34318037, valid_loss: 0.43074651, time: [5.03], best model: 0\n",
      "Epoch: 17, train_loss: 0.33611507, valid_loss: 0.42941832, time: [5.03], best model: 0\n",
      "Epoch: 18, train_loss: 0.32850279, valid_loss: 0.41744925, time: [5.01], best model: 1\n",
      "Epoch: 19, train_loss: 0.32857231, valid_loss: 0.43343641, time: [5.02], best model: 0\n",
      "Epoch: 20, train_loss: 0.30637755, valid_loss: 0.41261286, time: [5.02], best model: 1\n",
      "Epoch: 21, train_loss: 0.30507152, valid_loss: 0.42895121, time: [5.09], best model: 0\n",
      "Epoch: 22, train_loss: 0.29611953, valid_loss: 0.44045255, time: [5.05], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "New Best Score: 69.44 @ hyperparams = {'cell_size': 58, 'hidden_size': 78, 'learning_rate': 0.004738759319792616, 'num_epochs': 37, 'patience': 3, 'batch_size': 59, 'early_stop_frac': 0.12481656543798395, 'seed': 4410}\n",
      "On sample 5 / 10 (hyperparams = {'cell_size': 59, 'hidden_size': 93, 'learning_rate': 0.06904675101784023, 'num_epochs': 72, 'patience': 5, 'batch_size': 52, 'early_stop_frac': 0.07804439920644052, 'seed': 649})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (rl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (hl): Linear(in_features=301, out_features=93, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=93, bias=True)\n",
      "  (fc): Linear(in_features=93, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.82741152, valid_loss: 0.84202701, time: [6.18], best model: 1\n",
      "Epoch: 1, train_loss: 0.75402114, valid_loss: 0.75440889, time: [6.23], best model: 1\n",
      "Epoch: 2, train_loss: 0.65993958, valid_loss: 0.68607205, time: [6.2], best model: 1\n",
      "Epoch: 3, train_loss: 0.60756006, valid_loss: 0.6029703, time: [6.15], best model: 1\n",
      "Epoch: 4, train_loss: 0.55920922, valid_loss: 0.56370396, time: [6.11], best model: 1\n",
      "Epoch: 5, train_loss: 0.51790803, valid_loss: 0.51726631, time: [6.16], best model: 1\n",
      "Epoch: 6, train_loss: 0.49905526, valid_loss: 0.48932132, time: [6.15], best model: 1\n",
      "Epoch: 7, train_loss: 0.47726925, valid_loss: 0.47482057, time: [6.13], best model: 1\n",
      "Epoch: 8, train_loss: 0.45785491, valid_loss: 0.45855188, time: [6.19], best model: 1\n",
      "Epoch: 9, train_loss: 0.42672537, valid_loss: 0.43738744, time: [6.14], best model: 1\n",
      "Epoch: 10, train_loss: 0.4057869, valid_loss: 0.41915952, time: [6.14], best model: 1\n",
      "Epoch: 11, train_loss: 0.39516916, valid_loss: 0.40505501, time: [6.13], best model: 1\n",
      "Epoch: 12, train_loss: 0.38264052, valid_loss: 0.38873264, time: [6.17], best model: 1\n",
      "Epoch: 13, train_loss: 0.3685923, valid_loss: 0.38752114, time: [6.13], best model: 1\n",
      "Epoch: 14, train_loss: 0.35028168, valid_loss: 0.37843359, time: [6.16], best model: 1\n",
      "Epoch: 15, train_loss: 0.34730837, valid_loss: 0.37647288, time: [6.14], best model: 1\n",
      "Epoch: 16, train_loss: 0.33407312, valid_loss: 0.36775086, time: [6.13], best model: 1\n",
      "Epoch: 17, train_loss: 0.32414145, valid_loss: 0.36145255, time: [6.14], best model: 1\n",
      "Epoch: 18, train_loss: 0.31868735, valid_loss: 0.37546104, time: [6.17], best model: 0\n",
      "Epoch: 19, train_loss: 0.31693472, valid_loss: 0.37361791, time: [6.19], best model: 0\n",
      "Epoch: 20, train_loss: 0.30011314, valid_loss: 0.381601, time: [6.15], best model: 0\n",
      "Epoch: 21, train_loss: 0.28980585, valid_loss: 0.37774995, time: [6.09], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "On sample 6 / 10 (hyperparams = {'cell_size': 61, 'hidden_size': 71, 'learning_rate': 0.0437304802367127, 'num_epochs': 16, 'patience': 6, 'batch_size': 46, 'early_stop_frac': 0.12892793284514886, 'seed': 9505})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (rl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (hl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=71, bias=True)\n",
      "  (fc): Linear(in_features=71, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.84510166, valid_loss: 0.85852185, time: [5.29], best model: 1\n",
      "Epoch: 1, train_loss: 0.74534741, valid_loss: 0.75480149, time: [5.34], best model: 1\n",
      "Epoch: 2, train_loss: 0.67011823, valid_loss: 0.66399887, time: [5.27], best model: 1\n",
      "Epoch: 3, train_loss: 0.60292866, valid_loss: 0.60888978, time: [5.29], best model: 1\n",
      "Epoch: 4, train_loss: 0.55410037, valid_loss: 0.56110483, time: [5.27], best model: 1\n",
      "Epoch: 5, train_loss: 0.50940973, valid_loss: 0.52428143, time: [5.27], best model: 1\n",
      "Epoch: 6, train_loss: 0.48066066, valid_loss: 0.49520384, time: [5.29], best model: 1\n",
      "Epoch: 7, train_loss: 0.4572904, valid_loss: 0.47609828, time: [5.31], best model: 1\n",
      "Epoch: 8, train_loss: 0.44014933, valid_loss: 0.45698866, time: [5.31], best model: 1\n",
      "Epoch: 9, train_loss: 0.41644585, valid_loss: 0.44257661, time: [5.31], best model: 1\n",
      "Epoch: 10, train_loss: 0.39989019, valid_loss: 0.43637303, time: [5.3], best model: 1\n",
      "Epoch: 11, train_loss: 0.38863574, valid_loss: 0.41892083, time: [5.38], best model: 1\n",
      "Epoch: 12, train_loss: 0.37381015, valid_loss: 0.40753757, time: [5.59], best model: 1\n",
      "Epoch: 13, train_loss: 0.36221624, valid_loss: 0.40490215, time: [5.45], best model: 1\n",
      "Epoch: 14, train_loss: 0.35768664, valid_loss: 0.39635488, time: [5.59], best model: 1\n",
      "Epoch: 15, train_loss: 0.34755397, valid_loss: 0.40193625, time: [5.87], best model: 0\n",
      "New Best Score: 73.23 @ hyperparams = {'cell_size': 61, 'hidden_size': 71, 'learning_rate': 0.0437304802367127, 'num_epochs': 16, 'patience': 6, 'batch_size': 46, 'early_stop_frac': 0.12892793284514886, 'seed': 9505}\n",
      "On sample 7 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 90, 'learning_rate': 0.05786898284457517, 'num_epochs': 143, 'patience': 6, 'batch_size': 47, 'early_stop_frac': 0.06032260065776421, 'seed': 7587})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (rl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (hl): Linear(in_features=298, out_features=90, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=90, bias=True)\n",
      "  (fc): Linear(in_features=90, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.8364679, valid_loss: 0.83872573, time: [6.58], best model: 1\n",
      "Epoch: 1, train_loss: 0.72183688, valid_loss: 0.70359, time: [6.83], best model: 1\n",
      "Epoch: 2, train_loss: 0.62732522, valid_loss: 0.61491338, time: [6.9], best model: 1\n",
      "Epoch: 3, train_loss: 0.58746632, valid_loss: 0.56845089, time: [6.72], best model: 1\n",
      "Epoch: 4, train_loss: 0.53617521, valid_loss: 0.53698711, time: [7.], best model: 1\n",
      "Epoch: 5, train_loss: 0.51273084, valid_loss: 0.50120719, time: [6.59], best model: 1\n",
      "Epoch: 6, train_loss: 0.48958576, valid_loss: 0.48931503, time: [6.95], best model: 1\n",
      "Epoch: 7, train_loss: 0.45615327, valid_loss: 0.47079062, time: [6.68], best model: 1\n",
      "Epoch: 8, train_loss: 0.43259271, valid_loss: 0.43938529, time: [6.7], best model: 1\n",
      "Epoch: 9, train_loss: 0.42135326, valid_loss: 0.42437637, time: [7.07], best model: 1\n",
      "Epoch: 10, train_loss: 0.39241119, valid_loss: 0.40643648, time: [7.1], best model: 1\n",
      "Epoch: 11, train_loss: 0.38489211, valid_loss: 0.4093494, time: [6.62], best model: 0\n",
      "Epoch: 12, train_loss: 0.35901332, valid_loss: 0.3912615, time: [6.6], best model: 1\n",
      "Epoch: 13, train_loss: 0.35041825, valid_loss: 0.38047179, time: [6.39], best model: 1\n",
      "Epoch: 14, train_loss: 0.34324344, valid_loss: 0.38477667, time: [6.38], best model: 0\n",
      "Epoch: 15, train_loss: 0.33994873, valid_loss: 0.38153927, time: [6.38], best model: 0\n",
      "Epoch: 16, train_loss: 0.32310009, valid_loss: 0.38116292, time: [6.37], best model: 0\n",
      "Epoch: 17, train_loss: 0.32103521, valid_loss: 0.39071163, time: [6.38], best model: 0\n",
      "Epoch: 18, train_loss: 0.31480694, valid_loss: 0.37592717, time: [6.38], best model: 1\n",
      "Epoch: 19, train_loss: 0.30338416, valid_loss: 0.39115949, time: [6.38], best model: 0\n",
      "Epoch: 20, train_loss: 0.30005916, valid_loss: 0.39084641, time: [6.44], best model: 0\n",
      "Epoch: 21, train_loss: 0.28852771, valid_loss: 0.40314007, time: [6.75], best model: 0\n",
      "Epoch: 22, train_loss: 0.27819033, valid_loss: 0.40256969, time: [6.5], best model: 0\n",
      "Epoch: 23, train_loss: 0.27976771, valid_loss: 0.41725759, time: [6.52], best model: 0\n",
      "Early Stopped at Epoch: 24\n",
      "On sample 8 / 10 (hyperparams = {'cell_size': 65, 'hidden_size': 83, 'learning_rate': 0.016038693859523376, 'num_epochs': 75, 'patience': 5, 'batch_size': 61, 'early_stop_frac': 0.09478935261759053, 'seed': 1680})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (rl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (hl): Linear(in_features=291, out_features=83, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=83, bias=True)\n",
      "  (fc): Linear(in_features=83, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.82740902, valid_loss: 0.85059609, time: [5.51], best model: 1\n",
      "Epoch: 1, train_loss: 0.78467936, valid_loss: 0.76342967, time: [5.43], best model: 1\n",
      "Epoch: 2, train_loss: 0.68397033, valid_loss: 0.68387502, time: [5.48], best model: 1\n",
      "Epoch: 3, train_loss: 0.63113527, valid_loss: 0.62894966, time: [5.86], best model: 1\n",
      "Epoch: 4, train_loss: 0.58770064, valid_loss: 0.59488554, time: [5.63], best model: 1\n",
      "Epoch: 5, train_loss: 0.55811423, valid_loss: 0.54417081, time: [5.53], best model: 1\n",
      "Epoch: 6, train_loss: 0.52191334, valid_loss: 0.52495634, time: [5.56], best model: 1\n",
      "Epoch: 7, train_loss: 0.48148153, valid_loss: 0.48707521, time: [5.55], best model: 1\n",
      "Epoch: 8, train_loss: 0.47442901, valid_loss: 0.47094345, time: [5.68], best model: 1\n",
      "Epoch: 9, train_loss: 0.44924072, valid_loss: 0.47063365, time: [5.96], best model: 1\n",
      "Epoch: 10, train_loss: 0.44353942, valid_loss: 0.45751002, time: [5.61], best model: 1\n",
      "Epoch: 11, train_loss: 0.43011488, valid_loss: 0.44023315, time: [5.92], best model: 1\n",
      "Epoch: 12, train_loss: 0.41251035, valid_loss: 0.42832461, time: [5.68], best model: 1\n",
      "Epoch: 13, train_loss: 0.39058785, valid_loss: 0.41369183, time: [5.55], best model: 1\n",
      "Epoch: 14, train_loss: 0.38621362, valid_loss: 0.40393934, time: [5.91], best model: 1\n",
      "Epoch: 15, train_loss: 0.36933163, valid_loss: 0.4022634, time: [5.69], best model: 1\n",
      "Epoch: 16, train_loss: 0.35540506, valid_loss: 0.39373527, time: [5.54], best model: 1\n",
      "Epoch: 17, train_loss: 0.34900053, valid_loss: 0.3931852, time: [5.61], best model: 1\n",
      "Epoch: 18, train_loss: 0.34040878, valid_loss: 0.39350725, time: [5.62], best model: 0\n",
      "Epoch: 19, train_loss: 0.33304311, valid_loss: 0.38364123, time: [5.67], best model: 1\n",
      "Epoch: 20, train_loss: 0.32331053, valid_loss: 0.38342358, time: [5.5], best model: 1\n",
      "Epoch: 21, train_loss: 0.32048126, valid_loss: 0.39097431, time: [5.39], best model: 0\n",
      "Epoch: 22, train_loss: 0.31525335, valid_loss: 0.38405177, time: [5.4], best model: 0\n",
      "Epoch: 23, train_loss: 0.29664502, valid_loss: 0.38671496, time: [5.38], best model: 0\n",
      "Epoch: 24, train_loss: 0.28558476, valid_loss: 0.39311694, time: [5.35], best model: 0\n",
      "Early Stopped at Epoch: 25\n",
      "On sample 9 / 10 (hyperparams = {'cell_size': 50, 'hidden_size': 85, 'learning_rate': 0.021810148908487884, 'num_epochs': 23, 'patience': 4, 'batch_size': 55, 'early_stop_frac': 0.14085955030930958, 'seed': 7256})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (rl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (hl): Linear(in_features=293, out_features=85, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=85, bias=True)\n",
      "  (fc): Linear(in_features=85, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83684845, valid_loss: 0.84202108, time: [5.35], best model: 1\n",
      "Epoch: 1, train_loss: 0.74635351, valid_loss: 0.74879547, time: [5.31], best model: 1\n",
      "Epoch: 2, train_loss: 0.68235509, valid_loss: 0.67760686, time: [5.31], best model: 1\n",
      "Epoch: 3, train_loss: 0.61562922, valid_loss: 0.61870377, time: [5.42], best model: 1\n",
      "Epoch: 4, train_loss: 0.56388138, valid_loss: 0.58035268, time: [5.45], best model: 1\n",
      "Epoch: 5, train_loss: 0.53300639, valid_loss: 0.54395335, time: [5.56], best model: 1\n",
      "Epoch: 6, train_loss: 0.52087814, valid_loss: 0.52245458, time: [5.64], best model: 1\n",
      "Epoch: 7, train_loss: 0.49112249, valid_loss: 0.4865539, time: [5.55], best model: 1\n",
      "Epoch: 8, train_loss: 0.46556188, valid_loss: 0.47936096, time: [5.55], best model: 1\n",
      "Epoch: 9, train_loss: 0.45634832, valid_loss: 0.47077642, time: [6.04], best model: 1\n",
      "Epoch: 10, train_loss: 0.43844259, valid_loss: 0.4625855, time: [5.84], best model: 1\n",
      "Epoch: 11, train_loss: 0.41800031, valid_loss: 0.44439448, time: [5.8], best model: 1\n",
      "Epoch: 12, train_loss: 0.39144727, valid_loss: 0.43293177, time: [5.9], best model: 1\n",
      "Epoch: 13, train_loss: 0.38979696, valid_loss: 0.42165492, time: [5.84], best model: 1\n",
      "Epoch: 14, train_loss: 0.37742236, valid_loss: 0.40603795, time: [5.68], best model: 1\n",
      "Epoch: 15, train_loss: 0.36999535, valid_loss: 0.41506849, time: [5.61], best model: 0\n",
      "Epoch: 16, train_loss: 0.35758596, valid_loss: 0.39354637, time: [5.67], best model: 1\n",
      "Epoch: 17, train_loss: 0.33694934, valid_loss: 0.40328229, time: [5.55], best model: 0\n",
      "Epoch: 18, train_loss: 0.33261841, valid_loss: 0.40825829, time: [5.68], best model: 0\n",
      "Epoch: 19, train_loss: 0.32889519, valid_loss: 0.40588214, time: [5.8], best model: 0\n",
      "Early Stopped at Epoch: 20\n",
      "On sample 10 / 10 (hyperparams = {'cell_size': 66, 'hidden_size': 70, 'learning_rate': 0.08207445686755367, 'num_epochs': 130, 'patience': 4, 'batch_size': 51, 'early_stop_frac': 0.07936141483736796, 'seed': 7962})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (rl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (hl): Linear(in_features=278, out_features=70, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=70, bias=True)\n",
      "  (fc): Linear(in_features=70, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83142525, valid_loss: 0.85539308, time: [5.91], best model: 1\n",
      "Epoch: 1, train_loss: 0.72610775, valid_loss: 0.74103905, time: [5.65], best model: 1\n",
      "Epoch: 2, train_loss: 0.68256218, valid_loss: 0.68885364, time: [5.77], best model: 1\n",
      "Epoch: 3, train_loss: 0.61548965, valid_loss: 0.62352336, time: [5.85], best model: 1\n",
      "Epoch: 4, train_loss: 0.56684818, valid_loss: 0.58103025, time: [5.4], best model: 1\n",
      "Epoch: 5, train_loss: 0.51767043, valid_loss: 0.52631542, time: [5.94], best model: 1\n",
      "Epoch: 6, train_loss: 0.48070247, valid_loss: 0.50807571, time: [5.62], best model: 1\n",
      "Epoch: 7, train_loss: 0.47297402, valid_loss: 0.48550752, time: [5.71], best model: 1\n",
      "Epoch: 8, train_loss: 0.4454536, valid_loss: 0.46243224, time: [5.72], best model: 1\n",
      "Epoch: 9, train_loss: 0.4204059, valid_loss: 0.44452907, time: [5.42], best model: 1\n",
      "Epoch: 10, train_loss: 0.40464348, valid_loss: 0.43245826, time: [5.74], best model: 1\n",
      "Epoch: 11, train_loss: 0.38452224, valid_loss: 0.42651545, time: [5.46], best model: 1\n",
      "Epoch: 12, train_loss: 0.3707212, valid_loss: 0.40675208, time: [5.45], best model: 1\n",
      "Epoch: 13, train_loss: 0.36831539, valid_loss: 0.40105984, time: [5.43], best model: 1\n",
      "Epoch: 14, train_loss: 0.35448926, valid_loss: 0.40733009, time: [5.5], best model: 0\n",
      "Epoch: 15, train_loss: 0.34543554, valid_loss: 0.39715323, time: [5.56], best model: 1\n",
      "Epoch: 16, train_loss: 0.34424383, valid_loss: 0.40013486, time: [5.68], best model: 0\n",
      "Epoch: 17, train_loss: 0.32741453, valid_loss: 0.40804916, time: [5.42], best model: 0\n",
      "Epoch: 18, train_loss: 0.32940434, valid_loss: 0.40364057, time: [5.54], best model: 0\n",
      "Early Stopped at Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/tyl8krpx7t5c21z141cz0t2c0000gn/T/ipykernel_31323/1966726343.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (rl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (hl): Linear(in_features=279, out_features=71, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=71, bias=True)\n",
      "  (fc): Linear(in_features=71, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: 0.83319187, valid_loss: 0.85630299, time: [6.52], best model: 1\n",
      "Epoch: 1, train_loss: 0.72707785, valid_loss: 0.7333052, time: [6.5], best model: 1\n",
      "Epoch: 2, train_loss: 0.64345147, valid_loss: 0.65488089, time: [6.27], best model: 1\n",
      "Epoch: 3, train_loss: 0.5812159, valid_loss: 0.60430072, time: [6.24], best model: 1\n",
      "Epoch: 4, train_loss: 0.53294428, valid_loss: 0.54689649, time: [6.32], best model: 1\n",
      "Epoch: 5, train_loss: 0.48722102, valid_loss: 0.52736484, time: [6.17], best model: 1\n",
      "Epoch: 6, train_loss: 0.45936834, valid_loss: 0.48103189, time: [6.08], best model: 1\n",
      "Epoch: 7, train_loss: 0.4326433, valid_loss: 0.45537248, time: [6.01], best model: 1\n",
      "Epoch: 8, train_loss: 0.41590327, valid_loss: 0.44400732, time: [6.1], best model: 1\n",
      "Epoch: 9, train_loss: 0.38996917, valid_loss: 0.43015605, time: [6.03], best model: 1\n",
      "Epoch: 10, train_loss: 0.37868995, valid_loss: 0.41389073, time: [6.04], best model: 1\n",
      "Epoch: 11, train_loss: 0.3648901, valid_loss: 0.39945977, time: [6.03], best model: 1\n",
      "Epoch: 12, train_loss: 0.36765961, valid_loss: 0.40180617, time: [6.07], best model: 0\n",
      "Epoch: 13, train_loss: 0.3569863, valid_loss: 0.38699047, time: [6.03], best model: 1\n",
      "Epoch: 14, train_loss: 0.34963406, valid_loss: 0.39363278, time: [6.14], best model: 0\n",
      "Epoch: 15, train_loss: 0.33644981, valid_loss: 0.3971083, time: [6.54], best model: 0\n",
      "CPU times: user 22min 5s, sys: 38.7 s, total: 22min 43s\n",
      "Wall time: 22min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "if model_name not in results: results[model_name] = {}\n",
    "for t in [\n",
    "#    'mort_icu',\n",
    "#    'los_3', \n",
    "#    'mort_hosp', \n",
    "     'los_7'\n",
    "]:\n",
    "    if t not in results[model_name]: results[model_name][t] = {}\n",
    "    for n, X_train, X_dev, X_test in (\n",
    "        ('lvl2', lvl2_train, lvl2_dev, lvl2_test),\n",
    "#         ('raw', raw_train, raw_dev, raw_test)\n",
    "    ):\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        X_mean = np.nanmean(\n",
    "            to_3D_tensor(\n",
    "                X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "                np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "            ),\n",
    "            axis=0, keepdims=True\n",
    "        ).transpose([0, 2, 1])\n",
    "        base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "    \n",
    "        if n in results[model_name][t]:\n",
    "            if not RERUN: \n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                print(results[model_name][t][n])\n",
    "                continue\n",
    "            best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "            print(\"Loading best hyperparams\", best_hyperparams)\n",
    "        else:\n",
    "            best_s, best_hyperparams = -np.Inf, None\n",
    "            for i, hyperparams in enumerate(hyperparams_list):\n",
    "                print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "                early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "                batch_size = int(batch_size)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                all_train_subjects = list(\n",
    "                    np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "                )\n",
    "                N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "                train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "                early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "                X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "                Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "                X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "                Ys_train_early_stop = Ys_train[\n",
    "                    Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "                ]\n",
    "\n",
    "                train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "                early_stop_dataloader = prepare_dataloader(\n",
    "                    X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size\n",
    "                )\n",
    "                dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=batch_size)\n",
    "                test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "                model_hyperparams = copy.copy(base_params)\n",
    "                model_hyperparams.update(\n",
    "                    {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "                )\n",
    "                \n",
    "                batch_size = int(batch_size)\n",
    "                model = GRUD(**model_hyperparams)\n",
    "\n",
    "                best_model, _ = Train_Model(\n",
    "                    model, train_dataloader, early_stop_dataloader,\n",
    "                    **{k: v for k, v in hyperparams.items() if k in (\n",
    "                        'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                    )}\n",
    "                )\n",
    "\n",
    "                probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "                probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "                labels_dev        = np.concatenate(labels_dev)\n",
    "                s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "                if s > best_s:\n",
    "                    best_s, best_hyperparams = s, hyperparams\n",
    "                    print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "        ## Test\n",
    "        try:\n",
    "            np.random.seed(seed)\n",
    "            hyperparams = best_hyperparams # In case I forgot a replace below\n",
    "            early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "            batch_size = int(batch_size)\n",
    "            X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "\n",
    "            all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "            N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "            train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "            X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "            Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "            X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "            Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "            train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "            early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "            test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "            model_hyperparams = copy.copy(base_params)\n",
    "            model_hyperparams.update(\n",
    "                {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "            )\n",
    "            model = GRUD(**model_hyperparams)\n",
    "\n",
    "            best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "                model, train_dataloader, early_stop_dataloader,\n",
    "                **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "                    'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                )}\n",
    "            )\n",
    "\n",
    "            probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "            y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "            y_pred  = np.argmax(probabilities_test)\n",
    "            y_true  = np.concatenate(labels_test)\n",
    "\n",
    "            auc   = roc_auc_score(y_true, y_score)\n",
    "            auprc = average_precision_score(y_true, y_score)\n",
    "            acc   = accuracy_score(y_true, y_pred)\n",
    "            F1    = f1_score(y_true, y_pred)\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(auc, auprc, acc, F1)\n",
    "\n",
    "            results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "            #with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results for model GRU-D on target los_7 with representation lvl2\n",
      "0.6424193783744345 0.1384030084869607 0.9107946026986506 0.11851851851851852\n"
     ]
    }
   ],
   "source": [
    "y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "y_true  = np.concatenate(labels_test)\n",
    "\n",
    "y_score  = np.nan_to_num(y_score , nan=0, posinf=0)\n",
    "y_pred  = np.nan_to_num(y_pred , nan=0, posinf=0)\n",
    "y_true  = np.nan_to_num(y_true , nan=0, posinf=0)\n",
    "\n",
    "auc   = roc_auc_score(y_true, y_score)\n",
    "auprc = average_precision_score(y_true, y_score)\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "F1    = f1_score(y_true, y_pred)\n",
    "print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "print(auc, auprc, acc, F1)\n",
    "\n",
    "results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "with open('../scratch/mmd/baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
